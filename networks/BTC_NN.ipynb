{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1788/3660495534.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mAVG_OFFSETS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mOFFSET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mRESULT_OFFSET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mCHECKPOINT_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{CHECKPOINTS_FOLDER}training3/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from global_variables import *\n",
    "AVG_OFFSETS = list(range(2, 18))\n",
    "OFFSET = 2\n",
    "RESULT_OFFSET = 5\n",
    "CHECKPOINT_PATH = f'{CHECKPOINTS_FOLDER}training3/'\n",
    "SAVE_PATH = f'{CHECKPOINTS_FOLDER}training3/'\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.utils import normalize\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainset(file, avg_offsets = [10, 20, 35], offset = 15, result_offset = 7):\n",
    "    global train_array\n",
    "    with open(file, 'r') as train_file:\n",
    "        for line in train_file:\n",
    "            train_array = line.split(',')\n",
    "    \n",
    "    train_array = list(map(float, train_array))\n",
    "\n",
    "    result_set = np.zeros(shape = (len(train_array) - max( max(avg_offsets), offset ) - result_offset , 1))\n",
    "    print(np.shape(result_set))\n",
    "    for num in range(len(result_set)):\n",
    "        summ = sum(train_array[num + max(max(avg_offsets), offset) : num + max(max(avg_offsets), offset) + result_offset]) / RESULT_OFFSET\n",
    "        if train_array[num + max(max(avg_offsets), offset)] - summ > 0:\n",
    "            result_set[num, 0] = 1\n",
    "        else:\n",
    "            result_set[num, 0] = 0\n",
    "    \n",
    "    train_set = np.zeros(( len(train_array) - max(max(avg_offsets), offset) - result_offset, len(avg_offsets) + offset ))\n",
    "    for position in range(len(train_set)):\n",
    "        train_set[position] = fill_single_pos(train_array, avg_offsets, offset, position + max(max(avg_offsets), offset))\n",
    "    \n",
    "    #result_set /= np.amax(train_set)\n",
    "    #train_set /= np.amax(train_set)\n",
    "    np.savetxt(f'{TRAINSETS_FOLDER}trainset.txt', train_set)\n",
    "    return train_set, result_set\n",
    "\n",
    "def fill_single_pos(train_array, avg_offsets, offset, position):\n",
    "\n",
    "    pos = np.zeros((len(avg_offsets) + offset))\n",
    "    for num in range(len(avg_offsets)):\n",
    "        pos[num] = (train_array[position] - sum(train_array[position - avg_offsets[num] + 1 : position + 1]) / avg_offsets[num])\n",
    "    \n",
    "    for num in range(offset):\n",
    "        pos[num + len(avg_offsets)] = (train_array[position] - train_array[position - num])\n",
    "\n",
    "    return pos\n",
    "\n",
    "def create_network():\n",
    "    net = Sequential()\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(120, activation = tf.nn.sigmoid))\n",
    "    net.add(Dense(120, activation = tf.nn.sigmoid))\n",
    "    net.add(Dense(1, activation = tf.nn.sigmoid))\n",
    "\n",
    "    net.compile(optimizer = 'adam',\n",
    "    loss = 'mean_absolute_error')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25107, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_trainset(f'{TRAINSETS_FOLDER}btc_hour.txt', AVG_OFFSETS, OFFSET, RESULT_OFFSET)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(SAVE_PATH, save_weights_only = True, verbose = 1)\n",
    "nn = create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22279fbd8e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.load_weights(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2553\n",
      "Epoch 1: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2551\n",
      "Epoch 2/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2529\n",
      "Epoch 2: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2526\n",
      "Epoch 3/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2559\n",
      "Epoch 3: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2558\n",
      "Epoch 4/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2487\n",
      "Epoch 4: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 5/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 5: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 6/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 6: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2450\n",
      "Epoch 7/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 7: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2449\n",
      "Epoch 8/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 8: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2451\n",
      "Epoch 9/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 9: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2478\n",
      "Epoch 10/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2511\n",
      "Epoch 10: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2522\n",
      "Epoch 11/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2565\n",
      "Epoch 11: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2564\n",
      "Epoch 12/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2545\n",
      "Epoch 12: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2552\n",
      "Epoch 13/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2510\n",
      "Epoch 13: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 14/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2505\n",
      "Epoch 14: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2504\n",
      "Epoch 15/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2455\n",
      "Epoch 15: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 16/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2523\n",
      "Epoch 16: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 17/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2561\n",
      "Epoch 17: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2564\n",
      "Epoch 18/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 18: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 19/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2475\n",
      "Epoch 19: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 20/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2496\n",
      "Epoch 20: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 21/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2526\n",
      "Epoch 21: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2530\n",
      "Epoch 22/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 22: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 23/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2552\n",
      "Epoch 23: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2551\n",
      "Epoch 24/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2577\n",
      "Epoch 24: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2575\n",
      "Epoch 25/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2569\n",
      "Epoch 25: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2572\n",
      "Epoch 26/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2572\n",
      "Epoch 26: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2574\n",
      "Epoch 27/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2509\n",
      "Epoch 27: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516\n",
      "Epoch 28/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 28: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 29/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "Epoch 29: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2512\n",
      "Epoch 30/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2531\n",
      "Epoch 30: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 31/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2533\n",
      "Epoch 31: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2542\n",
      "Epoch 32/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2580\n",
      "Epoch 32: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2582\n",
      "Epoch 33/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2570\n",
      "Epoch 33: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2575\n",
      "Epoch 34/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2533\n",
      "Epoch 34: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2519\n",
      "Epoch 35/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 35: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 36/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 36: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 37/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2490\n",
      "Epoch 37: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2494\n",
      "Epoch 38/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2451\n",
      "Epoch 38: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 39/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 39: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2483\n",
      "Epoch 40/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2446\n",
      "Epoch 40: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 41/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 41: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 42/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 42: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2444\n",
      "Epoch 43/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2453\n",
      "Epoch 43: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 44/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2446\n",
      "Epoch 44: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 45/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 45: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 46/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2462\n",
      "Epoch 46: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 47/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2540\n",
      "Epoch 47: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2542\n",
      "Epoch 48/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 48: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 49/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2412\n",
      "Epoch 49: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2423\n",
      "Epoch 50/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2453\n",
      "Epoch 50: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2460\n",
      "Epoch 51/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 51: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2462\n",
      "Epoch 52/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2489\n",
      "Epoch 52: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 53/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2466\n",
      "Epoch 53: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 54/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2478\n",
      "Epoch 54: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2479\n",
      "Epoch 55/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 55: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2429\n",
      "Epoch 56/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2399\n",
      "Epoch 56: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2402\n",
      "Epoch 57/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2440\n",
      "Epoch 57: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 58/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2453\n",
      "Epoch 58: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 59/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2512\n",
      "Epoch 59: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 60/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2531\n",
      "Epoch 60: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516\n",
      "Epoch 61/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2421\n",
      "Epoch 61: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 62/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2470\n",
      "Epoch 62: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 63/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2439\n",
      "Epoch 63: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 64/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2470\n",
      "Epoch 64: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 65/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 65: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2463\n",
      "Epoch 66/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2430\n",
      "Epoch 66: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 67/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2477\n",
      "Epoch 67: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 68/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2447\n",
      "Epoch 68: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 69/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2433\n",
      "Epoch 69: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 70/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2466\n",
      "Epoch 70: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 71/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2467\n",
      "Epoch 71: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2463\n",
      "Epoch 72/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2502\n",
      "Epoch 72: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2499\n",
      "Epoch 73/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2425\n",
      "Epoch 73: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2423\n",
      "Epoch 74/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2426\n",
      "Epoch 74: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 75/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2470\n",
      "Epoch 75: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 76/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2493\n",
      "Epoch 76: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 77/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2465\n",
      "Epoch 77: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 78/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 78: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2495\n",
      "Epoch 79/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 79: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 80/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 80: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 81/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2501\n",
      "Epoch 81: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2501\n",
      "Epoch 82/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 82: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 83/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2479\n",
      "Epoch 83: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2482\n",
      "Epoch 84/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2493\n",
      "Epoch 84: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2495\n",
      "Epoch 85/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2458\n",
      "Epoch 85: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 86/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 86: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 87/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 87: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 88/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2493\n",
      "Epoch 88: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 89/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2529\n",
      "Epoch 89: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2529\n",
      "Epoch 90/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2533\n",
      "Epoch 90: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2536\n",
      "Epoch 91/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 91: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 92/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2550\n",
      "Epoch 92: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2552\n",
      "Epoch 93/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2564\n",
      "Epoch 93: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2566\n",
      "Epoch 94/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2539\n",
      "Epoch 94: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2541\n",
      "Epoch 95/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2576\n",
      "Epoch 95: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2569\n",
      "Epoch 96/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2581\n",
      "Epoch 96: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2581\n",
      "Epoch 97/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2595\n",
      "Epoch 97: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2585\n",
      "Epoch 98/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2534\n",
      "Epoch 98: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 99/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2501\n",
      "Epoch 99: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 100/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 100: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 101/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2441\n",
      "Epoch 101: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2444\n",
      "Epoch 102/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 102: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 103/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2525\n",
      "Epoch 103: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 104/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2525\n",
      "Epoch 104: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2533\n",
      "Epoch 105/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2547\n",
      "Epoch 105: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2549\n",
      "Epoch 106/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2525\n",
      "Epoch 106: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 107/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 107: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 108/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2513\n",
      "Epoch 108: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 109/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2502\n",
      "Epoch 109: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2502\n",
      "Epoch 110/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2558\n",
      "Epoch 110: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2558\n",
      "Epoch 111/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2523\n",
      "Epoch 111: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 112/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2402\n",
      "Epoch 112: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2401\n",
      "Epoch 113/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2478\n",
      "Epoch 113: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 114/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 114: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 115/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 115: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 116/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2516\n",
      "Epoch 116: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516\n",
      "Epoch 117/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 117: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 118/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 118: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2489\n",
      "Epoch 119/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2501\n",
      "Epoch 119: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 120/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2557\n",
      "Epoch 120: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2559\n",
      "Epoch 121/10000\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2521\n",
      "Epoch 121: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 122/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 122: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 123/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2519\n",
      "Epoch 123: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2505\n",
      "Epoch 124/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2439\n",
      "Epoch 124: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2438\n",
      "Epoch 125/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2487\n",
      "Epoch 125: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2495\n",
      "Epoch 126/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 126: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2520\n",
      "Epoch 127/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2536\n",
      "Epoch 127: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2538\n",
      "Epoch 128/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2535\n",
      "Epoch 128: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 129/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2457\n",
      "Epoch 129: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 130/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2461\n",
      "Epoch 130: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2477\n",
      "Epoch 131/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2505\n",
      "Epoch 131: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2501\n",
      "Epoch 132/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2545\n",
      "Epoch 132: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2545\n",
      "Epoch 133/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2511\n",
      "Epoch 133: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 134/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2495\n",
      "Epoch 134: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2489\n",
      "Epoch 135/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 135: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2486\n",
      "Epoch 136/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2529\n",
      "Epoch 136: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2527\n",
      "Epoch 137/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 137: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 138/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2479\n",
      "Epoch 138: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 139/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2492\n",
      "Epoch 139: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 140/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 140: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 141/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 141: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2519\n",
      "Epoch 142/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2519\n",
      "Epoch 142: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 143/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2619\n",
      "Epoch 143: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2616\n",
      "Epoch 144/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2568\n",
      "Epoch 144: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2571\n",
      "Epoch 145/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2575\n",
      "Epoch 145: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2569\n",
      "Epoch 146/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2553\n",
      "Epoch 146: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2545\n",
      "Epoch 147/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2529\n",
      "Epoch 147: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2538\n",
      "Epoch 148/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2568\n",
      "Epoch 148: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2576\n",
      "Epoch 149/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2541\n",
      "Epoch 149: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2542\n",
      "Epoch 150/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2513\n",
      "Epoch 150: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 151/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2480\n",
      "Epoch 151: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 152/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2415\n",
      "Epoch 152: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2424\n",
      "Epoch 153/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2419\n",
      "Epoch 153: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2423\n",
      "Epoch 154/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "Epoch 154: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 155/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2395\n",
      "Epoch 155: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2393\n",
      "Epoch 156/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2415\n",
      "Epoch 156: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 157/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2534\n",
      "Epoch 157: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 158/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2567\n",
      "Epoch 158: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2573\n",
      "Epoch 159/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2614\n",
      "Epoch 159: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2609\n",
      "Epoch 160/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2584\n",
      "Epoch 160: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2580\n",
      "Epoch 161/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2611\n",
      "Epoch 161: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2616\n",
      "Epoch 162/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2661\n",
      "Epoch 162: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2662\n",
      "Epoch 163/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2608\n",
      "Epoch 163: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2613\n",
      "Epoch 164/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2572\n",
      "Epoch 164: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2573\n",
      "Epoch 165/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2538\n",
      "Epoch 165: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2542\n",
      "Epoch 166/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2512\n",
      "Epoch 166: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 167/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 167: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 168/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2490\n",
      "Epoch 168: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 169/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 169: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516\n",
      "Epoch 170/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2545\n",
      "Epoch 170: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2545\n",
      "Epoch 171/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2547\n",
      "Epoch 171: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2549\n",
      "Epoch 172/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 172: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2519\n",
      "Epoch 173/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 173: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 174/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2524\n",
      "Epoch 174: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 175/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2466\n",
      "Epoch 175: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 176/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2474\n",
      "Epoch 176: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 177/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2525\n",
      "Epoch 177: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2527\n",
      "Epoch 178/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 178: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 179/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2510\n",
      "Epoch 179: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 180/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2471\n",
      "Epoch 180: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 181/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 181: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2434\n",
      "Epoch 182/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2506\n",
      "Epoch 182: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 183/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2445\n",
      "Epoch 183: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 184/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2485\n",
      "Epoch 184: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2485\n",
      "Epoch 185/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2461\n",
      "Epoch 185: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2461\n",
      "Epoch 186/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2470\n",
      "Epoch 186: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2469\n",
      "Epoch 187/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "Epoch 187: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2504\n",
      "Epoch 188/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2474\n",
      "Epoch 188: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 189/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2558\n",
      "Epoch 189: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2555\n",
      "Epoch 190/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2599\n",
      "Epoch 190: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2603\n",
      "Epoch 191/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2566\n",
      "Epoch 191: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2574\n",
      "Epoch 192/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2502\n",
      "Epoch 192: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 193/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2515\n",
      "Epoch 193: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 194/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2571\n",
      "Epoch 194: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2567\n",
      "Epoch 195/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2527\n",
      "Epoch 195: saving model to training3\\\n",
      "750/750 [==============================] - 1s 929us/step - loss: 0.2522\n",
      "Epoch 196/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2513\n",
      "Epoch 196: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 197/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2492\n",
      "Epoch 197: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 198/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2529\n",
      "Epoch 198: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 199/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2533\n",
      "Epoch 199: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2535\n",
      "Epoch 200/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2517\n",
      "Epoch 200: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2520\n",
      "Epoch 201/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2490\n",
      "Epoch 201: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 202/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 202: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 203/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 203: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 204/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2513\n",
      "Epoch 204: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2514\n",
      "Epoch 205/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2451\n",
      "Epoch 205: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 206/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2440\n",
      "Epoch 206: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 207/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 207: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 208/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2524\n",
      "Epoch 208: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2525\n",
      "Epoch 209/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2518\n",
      "Epoch 209: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 210/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2517\n",
      "Epoch 210: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 211/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2568\n",
      "Epoch 211: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2555\n",
      "Epoch 212/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2503\n",
      "Epoch 212: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 213/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2535\n",
      "Epoch 213: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2533\n",
      "Epoch 214/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2499\n",
      "Epoch 214: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 215/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2546\n",
      "Epoch 215: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2544\n",
      "Epoch 216/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2543\n",
      "Epoch 216: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2539\n",
      "Epoch 217/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2502\n",
      "Epoch 217: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 218/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2517\n",
      "Epoch 218: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2512\n",
      "Epoch 219/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2533\n",
      "Epoch 219: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2527\n",
      "Epoch 220/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2557\n",
      "Epoch 220: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2558\n",
      "Epoch 221/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2517\n",
      "Epoch 221: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 222/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2499\n",
      "Epoch 222: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2504\n",
      "Epoch 223/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2551\n",
      "Epoch 223: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2539\n",
      "Epoch 224/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2550\n",
      "Epoch 224: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2543\n",
      "Epoch 225/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2498\n",
      "Epoch 225: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2502\n",
      "Epoch 226/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2511\n",
      "Epoch 226: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2501\n",
      "Epoch 227/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 227: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 228/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2449\n",
      "Epoch 228: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 229/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2444\n",
      "Epoch 229: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 230/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 230: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 231/10000\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2456\n",
      "Epoch 231: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 232/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "Epoch 232: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 233/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2503\n",
      "Epoch 233: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 234/10000\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2570\n",
      "Epoch 234: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2568\n",
      "Epoch 235/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2592\n",
      "Epoch 235: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2589\n",
      "Epoch 236/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2635\n",
      "Epoch 236: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2640\n",
      "Epoch 237/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2602\n",
      "Epoch 237: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2610\n",
      "Epoch 238/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2542\n",
      "Epoch 238: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2544\n",
      "Epoch 239/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2587\n",
      "Epoch 239: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2585\n",
      "Epoch 240/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2540\n",
      "Epoch 240: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2542\n",
      "Epoch 241/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2496\n",
      "Epoch 241: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2495\n",
      "Epoch 242/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2519\n",
      "Epoch 242: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 243/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2530\n",
      "Epoch 243: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 244/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2504\n",
      "Epoch 244: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2501\n",
      "Epoch 245/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2585\n",
      "Epoch 245: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2589\n",
      "Epoch 246/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2571\n",
      "Epoch 246: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2570\n",
      "Epoch 247/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2556\n",
      "Epoch 247: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2559\n",
      "Epoch 248/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2527\n",
      "Epoch 248: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2538\n",
      "Epoch 249/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2537\n",
      "Epoch 249: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2536\n",
      "Epoch 250/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2498\n",
      "Epoch 250: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 251/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2495\n",
      "Epoch 251: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 252/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2483\n",
      "Epoch 252: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 253/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 253: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2448\n",
      "Epoch 254/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2513\n",
      "Epoch 254: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 255/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2431\n",
      "Epoch 255: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 256/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2454\n",
      "Epoch 256: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 257/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "Epoch 257: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 258/10000\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2512\n",
      "Epoch 258: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 259/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2540\n",
      "Epoch 259: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2531\n",
      "Epoch 260/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2478\n",
      "Epoch 260: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 261/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2464\n",
      "Epoch 261: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 262/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2435\n",
      "Epoch 262: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 263/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 263: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2467\n",
      "Epoch 264/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2495\n",
      "Epoch 264: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2496\n",
      "Epoch 265/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 265: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2491\n",
      "Epoch 266/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2466\n",
      "Epoch 266: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2466\n",
      "Epoch 267/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 267: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 268/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2431\n",
      "Epoch 268: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2429\n",
      "Epoch 269/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2411\n",
      "Epoch 269: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2410\n",
      "Epoch 270/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 270: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2434\n",
      "Epoch 271/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2590\n",
      "Epoch 271: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2594\n",
      "Epoch 272/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2635\n",
      "Epoch 272: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2637\n",
      "Epoch 273/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2580\n",
      "Epoch 273: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2584\n",
      "Epoch 274/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2542\n",
      "Epoch 274: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2549\n",
      "Epoch 275/10000\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2492\n",
      "Epoch 275: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 276/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2494\n",
      "Epoch 276: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2507\n",
      "Epoch 277/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2519\n",
      "Epoch 277: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2521\n",
      "Epoch 278/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2514\n",
      "Epoch 278: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 279/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2547\n",
      "Epoch 279: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2532\n",
      "Epoch 280/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2514\n",
      "Epoch 280: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 281/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2489\n",
      "Epoch 281: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 282/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2529\n",
      "Epoch 282: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2529\n",
      "Epoch 283/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2560\n",
      "Epoch 283: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2561\n",
      "Epoch 284/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2568\n",
      "Epoch 284: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2561\n",
      "Epoch 285/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 285: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2482\n",
      "Epoch 286/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 286: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2522\n",
      "Epoch 287/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2498\n",
      "Epoch 287: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 288/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2471\n",
      "Epoch 288: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2470\n",
      "Epoch 289/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2501\n",
      "Epoch 289: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2493\n",
      "Epoch 290/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 290: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 291/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2500\n",
      "Epoch 291: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2501\n",
      "Epoch 292/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2500\n",
      "Epoch 292: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 293/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2470\n",
      "Epoch 293: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 294/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2543\n",
      "Epoch 294: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2542\n",
      "Epoch 295/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2537\n",
      "Epoch 295: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2549\n",
      "Epoch 296/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2555\n",
      "Epoch 296: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2571\n",
      "Epoch 297/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2503\n",
      "Epoch 297: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2508\n",
      "Epoch 298/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2479\n",
      "Epoch 298: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 299/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2505\n",
      "Epoch 299: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2500\n",
      "Epoch 300/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2517\n",
      "Epoch 300: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 301/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2543\n",
      "Epoch 301: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2542\n",
      "Epoch 302/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 302: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516\n",
      "Epoch 303/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 303: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 304/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2470\n",
      "Epoch 304: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 305/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2451\n",
      "Epoch 305: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 306/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2507\n",
      "Epoch 306: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2509\n",
      "Epoch 307/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2582\n",
      "Epoch 307: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2587\n",
      "Epoch 308/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2606\n",
      "Epoch 308: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2595\n",
      "Epoch 309/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2568\n",
      "Epoch 309: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2569\n",
      "Epoch 310/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2526\n",
      "Epoch 310: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2525\n",
      "Epoch 311/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2507\n",
      "Epoch 311: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 312/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2569\n",
      "Epoch 312: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2570\n",
      "Epoch 313/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2503\n",
      "Epoch 313: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 314/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2478\n",
      "Epoch 314: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 315/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2483\n",
      "Epoch 315: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 316/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2495\n",
      "Epoch 316: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2505\n",
      "Epoch 317/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2497\n",
      "Epoch 317: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 318/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2507\n",
      "Epoch 318: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2510\n",
      "Epoch 319/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2557\n",
      "Epoch 319: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2559\n",
      "Epoch 320/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2575\n",
      "Epoch 320: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2572\n",
      "Epoch 321/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2530\n",
      "Epoch 321: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2535\n",
      "Epoch 322/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2573\n",
      "Epoch 322: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2579\n",
      "Epoch 323/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2564\n",
      "Epoch 323: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2561\n",
      "Epoch 324/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2528\n",
      "Epoch 324: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2531\n",
      "Epoch 325/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2523\n",
      "Epoch 325: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2522\n",
      "Epoch 326/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2503\n",
      "Epoch 326: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 327/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2610\n",
      "Epoch 327: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2607\n",
      "Epoch 328/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2646\n",
      "Epoch 328: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2646\n",
      "Epoch 329/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2582\n",
      "Epoch 329: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2591\n",
      "Epoch 330/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2550\n",
      "Epoch 330: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2549\n",
      "Epoch 331/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 331: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2522\n",
      "Epoch 332/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2540\n",
      "Epoch 332: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2539\n",
      "Epoch 333/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2560\n",
      "Epoch 333: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2560\n",
      "Epoch 334/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2552\n",
      "Epoch 334: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2550\n",
      "Epoch 335/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 335: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 336/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2565\n",
      "Epoch 336: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2568\n",
      "Epoch 337/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2505\n",
      "Epoch 337: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2507\n",
      "Epoch 338/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2514\n",
      "Epoch 338: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2507\n",
      "Epoch 339/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2482\n",
      "Epoch 339: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2479\n",
      "Epoch 340/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2501\n",
      "Epoch 340: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2499\n",
      "Epoch 341/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2477\n",
      "Epoch 341: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2486\n",
      "Epoch 342/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 342: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2486\n",
      "Epoch 343/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2525\n",
      "Epoch 343: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2524\n",
      "Epoch 344/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2514\n",
      "Epoch 344: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2510\n",
      "Epoch 345/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2460\n",
      "Epoch 345: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2458\n",
      "Epoch 346/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 346: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2437\n",
      "Epoch 347/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2463\n",
      "Epoch 347: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2465\n",
      "Epoch 348/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2480\n",
      "Epoch 348: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 349/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2469\n",
      "Epoch 349: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 350/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 350: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2471\n",
      "Epoch 351/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 351: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 352/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2511\n",
      "Epoch 352: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2517\n",
      "Epoch 353/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2589\n",
      "Epoch 353: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2596\n",
      "Epoch 354/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2592\n",
      "Epoch 354: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2603\n",
      "Epoch 355/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2541\n",
      "Epoch 355: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2543\n",
      "Epoch 356/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2542\n",
      "Epoch 356: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2539\n",
      "Epoch 357/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2538\n",
      "Epoch 357: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2538\n",
      "Epoch 358/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2580\n",
      "Epoch 358: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2580\n",
      "Epoch 359/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2538\n",
      "Epoch 359: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2546\n",
      "Epoch 360/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2554\n",
      "Epoch 360: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2551\n",
      "Epoch 361/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2557\n",
      "Epoch 361: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2565\n",
      "Epoch 362/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2552\n",
      "Epoch 362: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2549\n",
      "Epoch 363/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2605\n",
      "Epoch 363: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2599\n",
      "Epoch 364/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2539\n",
      "Epoch 364: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 365/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2477\n",
      "Epoch 365: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 366/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2440\n",
      "Epoch 366: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 367/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2482\n",
      "Epoch 367: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2479\n",
      "Epoch 368/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2489\n",
      "Epoch 368: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 369/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2486\n",
      "Epoch 369: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 370/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2582\n",
      "Epoch 370: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2582\n",
      "Epoch 371/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2514\n",
      "Epoch 371: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 372/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 372: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2438\n",
      "Epoch 373/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2429\n",
      "Epoch 373: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2430\n",
      "Epoch 374/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2441\n",
      "Epoch 374: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2441\n",
      "Epoch 375/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 375: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 376/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2461\n",
      "Epoch 376: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2461\n",
      "Epoch 377/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2507\n",
      "Epoch 377: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 378/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2518\n",
      "Epoch 378: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2518\n",
      "Epoch 379/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2500\n",
      "Epoch 379: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2504\n",
      "Epoch 380/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2509\n",
      "Epoch 380: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2505\n",
      "Epoch 381/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 381: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2524\n",
      "Epoch 382/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2462\n",
      "Epoch 382: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 383/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 383: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2469\n",
      "Epoch 384/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2467\n",
      "Epoch 384: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 385/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 385: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2488\n",
      "Epoch 386/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2478\n",
      "Epoch 386: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2482\n",
      "Epoch 387/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2498\n",
      "Epoch 387: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2498\n",
      "Epoch 388/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2447\n",
      "Epoch 388: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 389/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 389: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 390/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 390: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2451\n",
      "Epoch 391/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2459\n",
      "Epoch 391: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2453\n",
      "Epoch 392/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2443\n",
      "Epoch 392: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2449\n",
      "Epoch 393/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 393: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2510\n",
      "Epoch 394/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2503\n",
      "Epoch 394: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 395/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2490\n",
      "Epoch 395: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 396/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2498\n",
      "Epoch 396: saving model to training3\\\n",
      "750/750 [==============================] - 1s 962us/step - loss: 0.2508\n",
      "Epoch 397/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 397: saving model to training3\\\n",
      "750/750 [==============================] - 1s 894us/step - loss: 0.2474\n",
      "Epoch 398/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 398: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 399/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2500\n",
      "Epoch 399: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 400/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2522\n",
      "Epoch 400: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2520\n",
      "Epoch 401/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2558\n",
      "Epoch 401: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2562\n",
      "Epoch 402/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2572\n",
      "Epoch 402: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2570\n",
      "Epoch 403/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2536\n",
      "Epoch 403: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 404/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2550\n",
      "Epoch 404: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2556\n",
      "Epoch 405/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2580\n",
      "Epoch 405: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2580\n",
      "Epoch 406/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2623\n",
      "Epoch 406: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2619\n",
      "Epoch 407/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2569\n",
      "Epoch 407: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2566\n",
      "Epoch 408/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2524\n",
      "Epoch 408: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 409/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 409: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 410/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 410: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2477\n",
      "Epoch 411/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 411: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2494\n",
      "Epoch 412/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2461\n",
      "Epoch 412: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 413/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 413: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 414/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2457\n",
      "Epoch 414: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 415/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2417\n",
      "Epoch 415: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 416/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2385\n",
      "Epoch 416: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2386\n",
      "Epoch 417/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 417: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2460\n",
      "Epoch 418/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2447\n",
      "Epoch 418: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2445\n",
      "Epoch 419/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2451\n",
      "Epoch 419: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 420/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2460\n",
      "Epoch 420: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 421/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2550\n",
      "Epoch 421: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2556\n",
      "Epoch 422/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2584\n",
      "Epoch 422: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2589\n",
      "Epoch 423/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2543\n",
      "Epoch 423: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2555\n",
      "Epoch 424/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2528\n",
      "Epoch 424: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2529\n",
      "Epoch 425/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 425: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2518\n",
      "Epoch 426/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2466\n",
      "Epoch 426: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2475\n",
      "Epoch 427/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 427: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2433\n",
      "Epoch 428/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 428: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2426\n",
      "Epoch 429/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2427\n",
      "Epoch 429: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2422\n",
      "Epoch 430/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2411\n",
      "Epoch 430: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2407\n",
      "Epoch 431/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 431: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2463\n",
      "Epoch 432/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2460\n",
      "Epoch 432: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2462\n",
      "Epoch 433/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2449\n",
      "Epoch 433: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 434/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2489\n",
      "Epoch 434: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2483\n",
      "Epoch 435/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2470\n",
      "Epoch 435: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2471\n",
      "Epoch 436/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2490\n",
      "Epoch 436: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2490\n",
      "Epoch 437/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2463\n",
      "Epoch 437: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 438/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2501\n",
      "Epoch 438: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 439/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 439: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 440/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2446\n",
      "Epoch 440: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2453\n",
      "Epoch 441/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 441: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2445\n",
      "Epoch 442/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2430\n",
      "Epoch 442: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2424\n",
      "Epoch 443/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2402\n",
      "Epoch 443: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2406\n",
      "Epoch 444/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2410\n",
      "Epoch 444: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2401\n",
      "Epoch 445/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2433\n",
      "Epoch 445: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2429\n",
      "Epoch 446/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 446: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 447/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 447: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 448/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2536\n",
      "Epoch 448: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2532\n",
      "Epoch 449/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 449: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2522\n",
      "Epoch 450/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2482\n",
      "Epoch 450: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 451/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 451: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2489\n",
      "Epoch 452/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2531\n",
      "Epoch 452: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2527\n",
      "Epoch 453/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2519\n",
      "Epoch 453: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516\n",
      "Epoch 454/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2448\n",
      "Epoch 454: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2447\n",
      "Epoch 455/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 455: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 456/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2453\n",
      "Epoch 456: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 457/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 457: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2456\n",
      "Epoch 458/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2529\n",
      "Epoch 458: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2525\n",
      "Epoch 459/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 459: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 460/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 460: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 461/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2460\n",
      "Epoch 461: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 462/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2429\n",
      "Epoch 462: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2424\n",
      "Epoch 463/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2418\n",
      "Epoch 463: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 464/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2425\n",
      "Epoch 464: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 465/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2485\n",
      "Epoch 465: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2486\n",
      "Epoch 466/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2519\n",
      "Epoch 466: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2524\n",
      "Epoch 467/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2546\n",
      "Epoch 467: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2543\n",
      "Epoch 468/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2538\n",
      "Epoch 468: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2540\n",
      "Epoch 469/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2585\n",
      "Epoch 469: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2586\n",
      "Epoch 470/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2597\n",
      "Epoch 470: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2596\n",
      "Epoch 471/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2489\n",
      "Epoch 471: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 472/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2499\n",
      "Epoch 472: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2501\n",
      "Epoch 473/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2511\n",
      "Epoch 473: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2503\n",
      "Epoch 474/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2538\n",
      "Epoch 474: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2547\n",
      "Epoch 475/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2572\n",
      "Epoch 475: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2573\n",
      "Epoch 476/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2593\n",
      "Epoch 476: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2611\n",
      "Epoch 477/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2579\n",
      "Epoch 477: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2581\n",
      "Epoch 478/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2529\n",
      "Epoch 478: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2530\n",
      "Epoch 479/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2543\n",
      "Epoch 479: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 480/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2509\n",
      "Epoch 480: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 481/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2530\n",
      "Epoch 481: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2525\n",
      "Epoch 482/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 482: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 483/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2503\n",
      "Epoch 483: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2500\n",
      "Epoch 484/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2544\n",
      "Epoch 484: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2545\n",
      "Epoch 485/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2483\n",
      "Epoch 485: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2482\n",
      "Epoch 486/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2437\n",
      "Epoch 486: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 487/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 487: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 488/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2502\n",
      "Epoch 488: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2502\n",
      "Epoch 489/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2546\n",
      "Epoch 489: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2541\n",
      "Epoch 490/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2520\n",
      "Epoch 490: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2520\n",
      "Epoch 491/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 491: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2443\n",
      "Epoch 492/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2426\n",
      "Epoch 492: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2438\n",
      "Epoch 493/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 493: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2474\n",
      "Epoch 494/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2440\n",
      "Epoch 494: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 495/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2436\n",
      "Epoch 495: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 496/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2417\n",
      "Epoch 496: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2418\n",
      "Epoch 497/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2431\n",
      "Epoch 497: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2444\n",
      "Epoch 498/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2427\n",
      "Epoch 498: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2431\n",
      "Epoch 499/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2461\n",
      "Epoch 499: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2464\n",
      "Epoch 500/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2496\n",
      "Epoch 500: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2497\n",
      "Epoch 501/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2497\n",
      "Epoch 501: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2499\n",
      "Epoch 502/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2527\n",
      "Epoch 502: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2529\n",
      "Epoch 503/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2495\n",
      "Epoch 503: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2496\n",
      "Epoch 504/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2491\n",
      "Epoch 504: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2497\n",
      "Epoch 505/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2514\n",
      "Epoch 505: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2506\n",
      "Epoch 506/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2518\n",
      "Epoch 506: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 507/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2558\n",
      "Epoch 507: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2556\n",
      "Epoch 508/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2566\n",
      "Epoch 508: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2570\n",
      "Epoch 509/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2518\n",
      "Epoch 509: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2520\n",
      "Epoch 510/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 510: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2475\n",
      "Epoch 511/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2429\n",
      "Epoch 511: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2433\n",
      "Epoch 512/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2480\n",
      "Epoch 512: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2489\n",
      "Epoch 513/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 513: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2493\n",
      "Epoch 514/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2502\n",
      "Epoch 514: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2499\n",
      "Epoch 515/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2464\n",
      "Epoch 515: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2463\n",
      "Epoch 516/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2557\n",
      "Epoch 516: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2559\n",
      "Epoch 517/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 517: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 518/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 518: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2502\n",
      "Epoch 519/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2546\n",
      "Epoch 519: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2552\n",
      "Epoch 520/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2568\n",
      "Epoch 520: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2577\n",
      "Epoch 521/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2561\n",
      "Epoch 521: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2572\n",
      "Epoch 522/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2551\n",
      "Epoch 522: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2550\n",
      "Epoch 523/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2555\n",
      "Epoch 523: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2557\n",
      "Epoch 524/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2532\n",
      "Epoch 524: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2535\n",
      "Epoch 525/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2559\n",
      "Epoch 525: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2559\n",
      "Epoch 526/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2490\n",
      "Epoch 526: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2493\n",
      "Epoch 527/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2491\n",
      "Epoch 527: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 528/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 528: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2433\n",
      "Epoch 529/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2486\n",
      "Epoch 529: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2490\n",
      "Epoch 530/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 530: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2461\n",
      "Epoch 531/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2509\n",
      "Epoch 531: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2505\n",
      "Epoch 532/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2498\n",
      "Epoch 532: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2494\n",
      "Epoch 533/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 533: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 534/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 534: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2474\n",
      "Epoch 535/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2483\n",
      "Epoch 535: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 536/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "Epoch 536: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 537/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2419\n",
      "Epoch 537: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 538/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2438\n",
      "Epoch 538: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 539/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2464\n",
      "Epoch 539: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 540/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 540: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 541/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2507\n",
      "Epoch 541: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 542/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 542: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 543/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2455\n",
      "Epoch 543: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 544/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2425\n",
      "Epoch 544: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 545/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2523\n",
      "Epoch 545: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2529\n",
      "Epoch 546/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2633\n",
      "Epoch 546: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2633\n",
      "Epoch 547/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2600\n",
      "Epoch 547: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2599\n",
      "Epoch 548/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2612\n",
      "Epoch 548: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2612\n",
      "Epoch 549/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2545\n",
      "Epoch 549: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 550/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "Epoch 550: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2507\n",
      "Epoch 551/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 551: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2472\n",
      "Epoch 552/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2457\n",
      "Epoch 552: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2458\n",
      "Epoch 553/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2415\n",
      "Epoch 553: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2417\n",
      "Epoch 554/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2402\n",
      "Epoch 554: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2403\n",
      "Epoch 555/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2424\n",
      "Epoch 555: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2426\n",
      "Epoch 556/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2413\n",
      "Epoch 556: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2414\n",
      "Epoch 557/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 557: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2471\n",
      "Epoch 558/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2498\n",
      "Epoch 558: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 559/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2524\n",
      "Epoch 559: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2524\n",
      "Epoch 560/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 560: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 561/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 561: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 562/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2444\n",
      "Epoch 562: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2452\n",
      "Epoch 563/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2537\n",
      "Epoch 563: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2540\n",
      "Epoch 564/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2507\n",
      "Epoch 564: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2514\n",
      "Epoch 565/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2500\n",
      "Epoch 565: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2511\n",
      "Epoch 566/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 566: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 567/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 567: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2468\n",
      "Epoch 568/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 568: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 569/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2445\n",
      "Epoch 569: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2447\n",
      "Epoch 570/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2493\n",
      "Epoch 570: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2502\n",
      "Epoch 571/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2547\n",
      "Epoch 571: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2549\n",
      "Epoch 572/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2519\n",
      "Epoch 572: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 573/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2486\n",
      "Epoch 573: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2489\n",
      "Epoch 574/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2487\n",
      "Epoch 574: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 575/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 575: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2495\n",
      "Epoch 576/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2497\n",
      "Epoch 576: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 577/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2517\n",
      "Epoch 577: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2516\n",
      "Epoch 578/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2480\n",
      "Epoch 578: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2475\n",
      "Epoch 579/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 579: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2469\n",
      "Epoch 580/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "Epoch 580: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2452\n",
      "Epoch 581/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2490\n",
      "Epoch 581: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2500\n",
      "Epoch 582/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2532\n",
      "Epoch 582: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 583/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2537\n",
      "Epoch 583: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2529\n",
      "Epoch 584/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2485\n",
      "Epoch 584: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 585/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2491\n",
      "Epoch 585: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2494\n",
      "Epoch 586/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2534\n",
      "Epoch 586: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2532\n",
      "Epoch 587/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2527\n",
      "Epoch 587: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2525\n",
      "Epoch 588/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2521\n",
      "Epoch 588: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 589/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2581\n",
      "Epoch 589: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2583\n",
      "Epoch 590/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2542\n",
      "Epoch 590: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2541\n",
      "Epoch 591/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 591: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2489\n",
      "Epoch 592/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2445\n",
      "Epoch 592: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2449\n",
      "Epoch 593/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2478\n",
      "Epoch 593: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 594/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2542\n",
      "Epoch 594: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 595/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2530\n",
      "Epoch 595: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2543\n",
      "Epoch 596/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2513\n",
      "Epoch 596: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2514\n",
      "Epoch 597/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 597: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 598/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2573\n",
      "Epoch 598: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2574\n",
      "Epoch 599/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2568\n",
      "Epoch 599: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2566\n",
      "Epoch 600/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2495\n",
      "Epoch 600: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2491\n",
      "Epoch 601/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2526\n",
      "Epoch 601: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2527\n",
      "Epoch 602/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2555\n",
      "Epoch 602: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2555\n",
      "Epoch 603/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2570\n",
      "Epoch 603: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2562\n",
      "Epoch 604/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2534\n",
      "Epoch 604: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2532\n",
      "Epoch 605/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2578\n",
      "Epoch 605: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2575\n",
      "Epoch 606/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2484\n",
      "Epoch 606: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 607/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2460\n",
      "Epoch 607: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 608/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2459\n",
      "Epoch 608: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2462\n",
      "Epoch 609/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2449\n",
      "Epoch 609: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2445\n",
      "Epoch 610/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2465\n",
      "Epoch 610: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2462\n",
      "Epoch 611/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2451\n",
      "Epoch 611: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 612/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 612: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2450\n",
      "Epoch 613/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2510\n",
      "Epoch 613: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2513\n",
      "Epoch 614/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2464\n",
      "Epoch 614: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 615/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2513\n",
      "Epoch 615: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2512\n",
      "Epoch 616/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 616: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 617/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2420\n",
      "Epoch 617: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 618/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2394\n",
      "Epoch 618: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2397\n",
      "Epoch 619/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2424\n",
      "Epoch 619: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2423\n",
      "Epoch 620/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2461\n",
      "Epoch 620: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2461\n",
      "Epoch 621/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2404\n",
      "Epoch 621: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 622/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2430\n",
      "Epoch 622: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 623/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2436\n",
      "Epoch 623: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2438\n",
      "Epoch 624/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 624: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 625/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2415\n",
      "Epoch 625: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2418\n",
      "Epoch 626/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2413\n",
      "Epoch 626: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2411\n",
      "Epoch 627/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2433\n",
      "Epoch 627: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2432\n",
      "Epoch 628/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2436\n",
      "Epoch 628: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 629/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2460\n",
      "Epoch 629: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 630/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2530\n",
      "Epoch 630: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2526\n",
      "Epoch 631/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 631: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2491\n",
      "Epoch 632/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2432\n",
      "Epoch 632: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 633/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2486\n",
      "Epoch 633: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 634/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2473\n",
      "Epoch 634: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 635/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 635: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 636/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 636: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 637/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 637: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2434\n",
      "Epoch 638/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2496\n",
      "Epoch 638: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2489\n",
      "Epoch 639/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 639: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2489\n",
      "Epoch 640/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2556\n",
      "Epoch 640: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2551\n",
      "Epoch 641/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2573\n",
      "Epoch 641: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2572\n",
      "Epoch 642/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2500\n",
      "Epoch 642: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2497\n",
      "Epoch 643/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 643: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2425\n",
      "Epoch 644/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2356\n",
      "Epoch 644: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2355\n",
      "Epoch 645/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2413\n",
      "Epoch 645: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2402\n",
      "Epoch 646/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2419\n",
      "Epoch 646: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2426\n",
      "Epoch 647/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2391\n",
      "Epoch 647: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2399\n",
      "Epoch 648/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2453\n",
      "Epoch 648: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 649/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 649: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2459\n",
      "Epoch 650/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 650: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2519\n",
      "Epoch 651/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2501\n",
      "Epoch 651: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2491\n",
      "Epoch 652/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2503\n",
      "Epoch 652: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2504\n",
      "Epoch 653/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2570\n",
      "Epoch 653: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2573\n",
      "Epoch 654/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2553\n",
      "Epoch 654: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2552\n",
      "Epoch 655/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 655: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2524\n",
      "Epoch 656/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2524\n",
      "Epoch 656: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 657/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2518\n",
      "Epoch 657: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 658/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2546\n",
      "Epoch 658: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2551\n",
      "Epoch 659/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2568\n",
      "Epoch 659: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2570\n",
      "Epoch 660/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2535\n",
      "Epoch 660: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2531\n",
      "Epoch 661/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2500\n",
      "Epoch 661: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 662/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 662: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2525\n",
      "Epoch 663/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2497\n",
      "Epoch 663: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2502\n",
      "Epoch 664/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2433\n",
      "Epoch 664: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 665/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2382\n",
      "Epoch 665: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2382\n",
      "Epoch 666/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 666: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2436\n",
      "Epoch 667/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 667: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2452\n",
      "Epoch 668/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2506\n",
      "Epoch 668: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2509\n",
      "Epoch 669/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2449\n",
      "Epoch 669: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2446\n",
      "Epoch 670/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 670: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2463\n",
      "Epoch 671/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2424\n",
      "Epoch 671: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2428\n",
      "Epoch 672/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2459\n",
      "Epoch 672: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2458\n",
      "Epoch 673/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 673: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2413\n",
      "Epoch 674/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2427\n",
      "Epoch 674: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2426\n",
      "Epoch 675/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 675: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2475\n",
      "Epoch 676/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2442\n",
      "Epoch 676: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 677/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 677: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 678/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2451\n",
      "Epoch 678: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2448\n",
      "Epoch 679/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2524\n",
      "Epoch 679: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2516\n",
      "Epoch 680/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2461\n",
      "Epoch 680: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2456\n",
      "Epoch 681/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 681: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2495\n",
      "Epoch 682/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2493\n",
      "Epoch 682: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 683/10000\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2514\n",
      "Epoch 683: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 684/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 684: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 685/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2498\n",
      "Epoch 685: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 686/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2533\n",
      "Epoch 686: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 687/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2546\n",
      "Epoch 687: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2541\n",
      "Epoch 688/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 688: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 689/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 689: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 690/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 690: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 691/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 691: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2489\n",
      "Epoch 692/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2513\n",
      "Epoch 692: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2515\n",
      "Epoch 693/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2467\n",
      "Epoch 693: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2485\n",
      "Epoch 694/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 694: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 695/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 695: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2474\n",
      "Epoch 696/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2446\n",
      "Epoch 696: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2444\n",
      "Epoch 697/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2427\n",
      "Epoch 697: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2430\n",
      "Epoch 698/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 698: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2443\n",
      "Epoch 699/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 699: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2461\n",
      "Epoch 700/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 700: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2426\n",
      "Epoch 701/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2443\n",
      "Epoch 701: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2441\n",
      "Epoch 702/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2418\n",
      "Epoch 702: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2416\n",
      "Epoch 703/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2417\n",
      "Epoch 703: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2421\n",
      "Epoch 704/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2381\n",
      "Epoch 704: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2381\n",
      "Epoch 705/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2425\n",
      "Epoch 705: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2423\n",
      "Epoch 706/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 706: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 707/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2489\n",
      "Epoch 707: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2494\n",
      "Epoch 708/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 708: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2465\n",
      "Epoch 709/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2421\n",
      "Epoch 709: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2429\n",
      "Epoch 710/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 710: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 711/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2499\n",
      "Epoch 711: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2493\n",
      "Epoch 712/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2499\n",
      "Epoch 712: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2505\n",
      "Epoch 713/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2514\n",
      "Epoch 713: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2517\n",
      "Epoch 714/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2542\n",
      "Epoch 714: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2543\n",
      "Epoch 715/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2545\n",
      "Epoch 715: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2547\n",
      "Epoch 716/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 716: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2522\n",
      "Epoch 717/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 717: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 718/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2500\n",
      "Epoch 718: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2494\n",
      "Epoch 719/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2524\n",
      "Epoch 719: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 720/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2464\n",
      "Epoch 720: saving model to training3\\\n",
      "750/750 [==============================] - 1s 916us/step - loss: 0.2463\n",
      "Epoch 721/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "Epoch 721: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 722/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2463\n",
      "Epoch 722: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 723/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2457\n",
      "Epoch 723: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 724/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2471\n",
      "Epoch 724: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2477\n",
      "Epoch 725/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2573\n",
      "Epoch 725: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2573\n",
      "Epoch 726/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 726: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2524\n",
      "Epoch 727/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2541\n",
      "Epoch 727: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2543\n",
      "Epoch 728/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2548\n",
      "Epoch 728: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2548\n",
      "Epoch 729/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2578\n",
      "Epoch 729: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2577\n",
      "Epoch 730/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2561\n",
      "Epoch 730: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2559\n",
      "Epoch 731/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2534\n",
      "Epoch 731: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 732/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 732: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2521\n",
      "Epoch 733/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2513\n",
      "Epoch 733: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 734/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2492\n",
      "Epoch 734: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 735/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2495\n",
      "Epoch 735: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 736/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2466\n",
      "Epoch 736: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2462\n",
      "Epoch 737/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2445\n",
      "Epoch 737: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 738/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2499\n",
      "Epoch 738: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 739/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2426\n",
      "Epoch 739: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2425\n",
      "Epoch 740/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2433\n",
      "Epoch 740: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2432\n",
      "Epoch 741/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 741: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 742/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2511\n",
      "Epoch 742: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 743/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2550\n",
      "Epoch 743: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2549\n",
      "Epoch 744/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2569\n",
      "Epoch 744: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2570\n",
      "Epoch 745/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2572\n",
      "Epoch 745: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2578\n",
      "Epoch 746/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2565\n",
      "Epoch 746: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2567\n",
      "Epoch 747/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2548\n",
      "Epoch 747: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2538\n",
      "Epoch 748/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 748: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2510\n",
      "Epoch 749/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2526\n",
      "Epoch 749: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 750/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2492\n",
      "Epoch 750: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 751/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 751: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2436\n",
      "Epoch 752/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2459\n",
      "Epoch 752: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 753/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2499\n",
      "Epoch 753: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2504\n",
      "Epoch 754/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 754: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 755/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2414\n",
      "Epoch 755: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2416\n",
      "Epoch 756/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2442\n",
      "Epoch 756: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 757/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 757: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 758/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "Epoch 758: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2514\n",
      "Epoch 759/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 759: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2522\n",
      "Epoch 760/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2541\n",
      "Epoch 760: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 761/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2478\n",
      "Epoch 761: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 762/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 762: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2481\n",
      "Epoch 763/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2529\n",
      "Epoch 763: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2530\n",
      "Epoch 764/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 764: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2521\n",
      "Epoch 765/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 765: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2494\n",
      "Epoch 766/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2556\n",
      "Epoch 766: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2554\n",
      "Epoch 767/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2552\n",
      "Epoch 767: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2550\n",
      "Epoch 768/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2527\n",
      "Epoch 768: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2528\n",
      "Epoch 769/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2489\n",
      "Epoch 769: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 770/10000\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2503\n",
      "Epoch 770: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2507\n",
      "Epoch 771/10000\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2516\n",
      "Epoch 771: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 772/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2460\n",
      "Epoch 772: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 773/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 773: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 774/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2463\n",
      "Epoch 774: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 775/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2552\n",
      "Epoch 775: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2550\n",
      "Epoch 776/10000\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2584\n",
      "Epoch 776: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2578\n",
      "Epoch 777/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2586\n",
      "Epoch 777: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2581\n",
      "Epoch 778/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2575\n",
      "Epoch 778: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2570\n",
      "Epoch 779/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2543\n",
      "Epoch 779: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2539\n",
      "Epoch 780/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2516\n",
      "Epoch 780: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2522\n",
      "Epoch 781/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2482\n",
      "Epoch 781: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2483\n",
      "Epoch 782/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2470\n",
      "Epoch 782: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 783/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 783: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2523\n",
      "Epoch 784/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2500\n",
      "Epoch 784: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 785/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2567\n",
      "Epoch 785: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2569\n",
      "Epoch 786/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2555\n",
      "Epoch 786: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2555\n",
      "Epoch 787/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2538\n",
      "Epoch 787: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 788/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2556\n",
      "Epoch 788: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2557\n",
      "Epoch 789/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2617\n",
      "Epoch 789: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2613\n",
      "Epoch 790/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2583\n",
      "Epoch 790: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2575\n",
      "Epoch 791/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2547\n",
      "Epoch 791: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2547\n",
      "Epoch 792/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2598\n",
      "Epoch 792: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2586\n",
      "Epoch 793/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2615\n",
      "Epoch 793: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2607\n",
      "Epoch 794/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2549\n",
      "Epoch 794: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2536\n",
      "Epoch 795/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 795: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 796/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2496\n",
      "Epoch 796: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 797/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 797: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 798/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2506\n",
      "Epoch 798: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 799/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2477\n",
      "Epoch 799: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2479\n",
      "Epoch 800/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2441\n",
      "Epoch 800: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2437\n",
      "Epoch 801/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 801: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 802/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 802: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2436\n",
      "Epoch 803/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2459\n",
      "Epoch 803: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 804/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2471\n",
      "Epoch 804: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 805/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 805: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 806/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2412\n",
      "Epoch 806: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2420\n",
      "Epoch 807/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 807: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2450\n",
      "Epoch 808/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "Epoch 808: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 809/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 809: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 810/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2467\n",
      "Epoch 810: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2466\n",
      "Epoch 811/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2474\n",
      "Epoch 811: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2477\n",
      "Epoch 812/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2505\n",
      "Epoch 812: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2512\n",
      "Epoch 813/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2512\n",
      "Epoch 813: saving model to training3\\\n",
      "750/750 [==============================] - 1s 971us/step - loss: 0.2511\n",
      "Epoch 814/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2433\n",
      "Epoch 814: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2432\n",
      "Epoch 815/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2506\n",
      "Epoch 815: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2508\n",
      "Epoch 816/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2464\n",
      "Epoch 816: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2461\n",
      "Epoch 817/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2497\n",
      "Epoch 817: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2503\n",
      "Epoch 818/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2485\n",
      "Epoch 818: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 819/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2464\n",
      "Epoch 819: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 820/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 820: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 821/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2466\n",
      "Epoch 821: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2461\n",
      "Epoch 822/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2439\n",
      "Epoch 822: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 823/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2443\n",
      "Epoch 823: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2450\n",
      "Epoch 824/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2613\n",
      "Epoch 824: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2607\n",
      "Epoch 825/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2588\n",
      "Epoch 825: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2599\n",
      "Epoch 826/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2622\n",
      "Epoch 826: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2618\n",
      "Epoch 827/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2625\n",
      "Epoch 827: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2625\n",
      "Epoch 828/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2623\n",
      "Epoch 828: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2624\n",
      "Epoch 829/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2550\n",
      "Epoch 829: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2560\n",
      "Epoch 830/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2545\n",
      "Epoch 830: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2541\n",
      "Epoch 831/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2554\n",
      "Epoch 831: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2555\n",
      "Epoch 832/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2571\n",
      "Epoch 832: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2577\n",
      "Epoch 833/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2552\n",
      "Epoch 833: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2552\n",
      "Epoch 834/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2497\n",
      "Epoch 834: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 835/10000\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2450\n",
      "Epoch 835: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 836/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2449\n",
      "Epoch 836: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 837/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2367\n",
      "Epoch 837: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2369\n",
      "Epoch 838/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2392\n",
      "Epoch 838: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2391\n",
      "Epoch 839/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2421\n",
      "Epoch 839: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2423\n",
      "Epoch 840/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2442\n",
      "Epoch 840: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 841/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2427\n",
      "Epoch 841: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 842/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2379\n",
      "Epoch 842: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2380\n",
      "Epoch 843/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2424\n",
      "Epoch 843: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 844/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 844: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2408\n",
      "Epoch 845/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2490\n",
      "Epoch 845: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 846/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2516\n",
      "Epoch 846: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2520\n",
      "Epoch 847/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2510\n",
      "Epoch 847: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 848/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2504\n",
      "Epoch 848: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 849/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2498\n",
      "Epoch 849: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 850/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2505\n",
      "Epoch 850: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2507\n",
      "Epoch 851/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2543\n",
      "Epoch 851: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2541\n",
      "Epoch 852/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2518\n",
      "Epoch 852: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2510\n",
      "Epoch 853/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 853: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 854/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2441\n",
      "Epoch 854: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 855/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2409\n",
      "Epoch 855: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2420\n",
      "Epoch 856/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2457\n",
      "Epoch 856: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 857/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "Epoch 857: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 858/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2480\n",
      "Epoch 858: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 859/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "Epoch 859: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2521\n",
      "Epoch 860/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2522\n",
      "Epoch 860: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 861/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2532\n",
      "Epoch 861: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2529\n",
      "Epoch 862/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2606\n",
      "Epoch 862: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2601\n",
      "Epoch 863/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2572\n",
      "Epoch 863: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2570\n",
      "Epoch 864/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2548\n",
      "Epoch 864: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2550\n",
      "Epoch 865/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2496\n",
      "Epoch 865: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 866/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 866: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 867/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2489\n",
      "Epoch 867: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 868/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2503\n",
      "Epoch 868: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 869/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2461\n",
      "Epoch 869: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2465\n",
      "Epoch 870/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2418\n",
      "Epoch 870: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2418\n",
      "Epoch 871/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2411\n",
      "Epoch 871: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2415\n",
      "Epoch 872/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2381\n",
      "Epoch 872: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2384\n",
      "Epoch 873/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2345\n",
      "Epoch 873: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2345\n",
      "Epoch 874/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2369\n",
      "Epoch 874: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2367\n",
      "Epoch 875/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2428\n",
      "Epoch 875: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 876/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2380\n",
      "Epoch 876: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2382\n",
      "Epoch 877/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2392\n",
      "Epoch 877: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2390\n",
      "Epoch 878/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 878: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2391\n",
      "Epoch 879/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2447\n",
      "Epoch 879: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 880/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2443\n",
      "Epoch 880: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 881/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2472\n",
      "Epoch 881: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 882/10000\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2503\n",
      "Epoch 882: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 883/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 883: saving model to training3\\\n",
      "750/750 [==============================] - 1s 998us/step - loss: 0.2491\n",
      "Epoch 884/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2416\n",
      "Epoch 884: saving model to training3\\\n",
      "750/750 [==============================] - 1s 945us/step - loss: 0.2426\n",
      "Epoch 885/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2453\n",
      "Epoch 885: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 886/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2432\n",
      "Epoch 886: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 887/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2426\n",
      "Epoch 887: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2436\n",
      "Epoch 888/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2484\n",
      "Epoch 888: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 889/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 889: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 890/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2484\n",
      "Epoch 890: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 891/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2456\n",
      "Epoch 891: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 892/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2429\n",
      "Epoch 892: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 893/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2433\n",
      "Epoch 893: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 894/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 894: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2444\n",
      "Epoch 895/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2448\n",
      "Epoch 895: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 896/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2450\n",
      "Epoch 896: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 897/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2484\n",
      "Epoch 897: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 898/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2407\n",
      "Epoch 898: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2406\n",
      "Epoch 899/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2363\n",
      "Epoch 899: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2368\n",
      "Epoch 900/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2367\n",
      "Epoch 900: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2363\n",
      "Epoch 901/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2384\n",
      "Epoch 901: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2381\n",
      "Epoch 902/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2405\n",
      "Epoch 902: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2401\n",
      "Epoch 903/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2379\n",
      "Epoch 903: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2381\n",
      "Epoch 904/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2398\n",
      "Epoch 904: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2392\n",
      "Epoch 905/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2446\n",
      "Epoch 905: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 906/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2484\n",
      "Epoch 906: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 907/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2486\n",
      "Epoch 907: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 908/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2498\n",
      "Epoch 908: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 909/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2459\n",
      "Epoch 909: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 910/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2462\n",
      "Epoch 910: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2460\n",
      "Epoch 911/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2521\n",
      "Epoch 911: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2514\n",
      "Epoch 912/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2506\n",
      "Epoch 912: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 913/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2501\n",
      "Epoch 913: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2502\n",
      "Epoch 914/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2547\n",
      "Epoch 914: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2552\n",
      "Epoch 915/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 915: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 916/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2446\n",
      "Epoch 916: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 917/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 917: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 918/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2451\n",
      "Epoch 918: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 919/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2467\n",
      "Epoch 919: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 920/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2455\n",
      "Epoch 920: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 921/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2432\n",
      "Epoch 921: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2432\n",
      "Epoch 922/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2480\n",
      "Epoch 922: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 923/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 923: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 924/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2480\n",
      "Epoch 924: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 925/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2528\n",
      "Epoch 925: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2526\n",
      "Epoch 926/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2566\n",
      "Epoch 926: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2571\n",
      "Epoch 927/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2512\n",
      "Epoch 927: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 928/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 928: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 929/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 929: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 930/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 930: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 931/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 931: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 932/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 932: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2458\n",
      "Epoch 933/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 933: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 934/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2416\n",
      "Epoch 934: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2408\n",
      "Epoch 935/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 935: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2441\n",
      "Epoch 936/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2431\n",
      "Epoch 936: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2429\n",
      "Epoch 937/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 937: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2456\n",
      "Epoch 938/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 938: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 939/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2380\n",
      "Epoch 939: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2386\n",
      "Epoch 940/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2380\n",
      "Epoch 940: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2379\n",
      "Epoch 941/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2404\n",
      "Epoch 941: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2405\n",
      "Epoch 942/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2397\n",
      "Epoch 942: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2406\n",
      "Epoch 943/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2443\n",
      "Epoch 943: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2444\n",
      "Epoch 944/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2452\n",
      "Epoch 944: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 945/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2451\n",
      "Epoch 945: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2452\n",
      "Epoch 946/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 946: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 947/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2426\n",
      "Epoch 947: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2426\n",
      "Epoch 948/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2498\n",
      "Epoch 948: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2501\n",
      "Epoch 949/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 949: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 950/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2432\n",
      "Epoch 950: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2437\n",
      "Epoch 951/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 951: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 952/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 952: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2440\n",
      "Epoch 953/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2420\n",
      "Epoch 953: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 954/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 954: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 955/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2463\n",
      "Epoch 955: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2467\n",
      "Epoch 956/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2467\n",
      "Epoch 956: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2463\n",
      "Epoch 957/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2422\n",
      "Epoch 957: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2431\n",
      "Epoch 958/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2449\n",
      "Epoch 958: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2454\n",
      "Epoch 959/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2445\n",
      "Epoch 959: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2443\n",
      "Epoch 960/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 960: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2435\n",
      "Epoch 961/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 961: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 962/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2432\n",
      "Epoch 962: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 963/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 963: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2432\n",
      "Epoch 964/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 964: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 965/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 965: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 966/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2465\n",
      "Epoch 966: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 967/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2465\n",
      "Epoch 967: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2462\n",
      "Epoch 968/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 968: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 969/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2425\n",
      "Epoch 969: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2426\n",
      "Epoch 970/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 970: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2448\n",
      "Epoch 971/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 971: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 972/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2412\n",
      "Epoch 972: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 973/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2439\n",
      "Epoch 973: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 974/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2415\n",
      "Epoch 974: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2411\n",
      "Epoch 975/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 975: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2472\n",
      "Epoch 976/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2421\n",
      "Epoch 976: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2414\n",
      "Epoch 977/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 977: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 978/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2457\n",
      "Epoch 978: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 979/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2423\n",
      "Epoch 979: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2424\n",
      "Epoch 980/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 980: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2415\n",
      "Epoch 981/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2380\n",
      "Epoch 981: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2385\n",
      "Epoch 982/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2408\n",
      "Epoch 982: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2409\n",
      "Epoch 983/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2424\n",
      "Epoch 983: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 984/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2477\n",
      "Epoch 984: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 985/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 985: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2453\n",
      "Epoch 986/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2480\n",
      "Epoch 986: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2465\n",
      "Epoch 987/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 987: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2479\n",
      "Epoch 988/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2437\n",
      "Epoch 988: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2439\n",
      "Epoch 989/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2436\n",
      "Epoch 989: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2436\n",
      "Epoch 990/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 990: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2440\n",
      "Epoch 991/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 991: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2459\n",
      "Epoch 992/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2492\n",
      "Epoch 992: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2494\n",
      "Epoch 993/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2524\n",
      "Epoch 993: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 994/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 994: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2436\n",
      "Epoch 995/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2404\n",
      "Epoch 995: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2403\n",
      "Epoch 996/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 996: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2463\n",
      "Epoch 997/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2374\n",
      "Epoch 997: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2372\n",
      "Epoch 998/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 998: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2438\n",
      "Epoch 999/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2410\n",
      "Epoch 999: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2428\n",
      "Epoch 1000/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2426\n",
      "Epoch 1000: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2428\n",
      "Epoch 1001/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 1001: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 1002/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2528\n",
      "Epoch 1002: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2526\n",
      "Epoch 1003/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2570\n",
      "Epoch 1003: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2570\n",
      "Epoch 1004/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2504\n",
      "Epoch 1004: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2502\n",
      "Epoch 1005/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2428\n",
      "Epoch 1005: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 1006/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1006: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1007/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2461\n",
      "Epoch 1007: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1008/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1008: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 1009/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2483\n",
      "Epoch 1009: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2479\n",
      "Epoch 1010/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2518\n",
      "Epoch 1010: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 1011/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2478\n",
      "Epoch 1011: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 1012/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1012: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 1013/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2428\n",
      "Epoch 1013: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2426\n",
      "Epoch 1014/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 1014: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2428\n",
      "Epoch 1015/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 1015: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 1016/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2512\n",
      "Epoch 1016: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2512\n",
      "Epoch 1017/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2471\n",
      "Epoch 1017: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2475\n",
      "Epoch 1018/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2426\n",
      "Epoch 1018: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2424\n",
      "Epoch 1019/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1019: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2418\n",
      "Epoch 1020/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2406\n",
      "Epoch 1020: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2403\n",
      "Epoch 1021/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2446\n",
      "Epoch 1021: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2450\n",
      "Epoch 1022/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 1022: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2479\n",
      "Epoch 1023/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1023: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2450\n",
      "Epoch 1024/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1024: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 1025/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2417\n",
      "Epoch 1025: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2415\n",
      "Epoch 1026/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2421\n",
      "Epoch 1026: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 1027/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 1027: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 1028/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2449\n",
      "Epoch 1028: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 1029/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2411\n",
      "Epoch 1029: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1030/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2466\n",
      "Epoch 1030: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 1031/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1031: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2413\n",
      "Epoch 1032/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1032: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2395\n",
      "Epoch 1033/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1033: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2408\n",
      "Epoch 1034/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1034: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2429\n",
      "Epoch 1035/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2382\n",
      "Epoch 1035: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2377\n",
      "Epoch 1036/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2384\n",
      "Epoch 1036: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 1037/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2421\n",
      "Epoch 1037: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 1038/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1038: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 1039/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1039: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2460\n",
      "Epoch 1040/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 1040: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 1041/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2392\n",
      "Epoch 1041: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2394\n",
      "Epoch 1042/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2384\n",
      "Epoch 1042: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2390\n",
      "Epoch 1043/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2384\n",
      "Epoch 1043: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2384\n",
      "Epoch 1044/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1044: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2400\n",
      "Epoch 1045/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2449\n",
      "Epoch 1045: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1046/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2427\n",
      "Epoch 1046: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 1047/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2449\n",
      "Epoch 1047: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 1048/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2506\n",
      "Epoch 1048: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 1049/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2484\n",
      "Epoch 1049: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2479\n",
      "Epoch 1050/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2457\n",
      "Epoch 1050: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 1051/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1051: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2505\n",
      "Epoch 1052/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2492\n",
      "Epoch 1052: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2489\n",
      "Epoch 1053/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 1053: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 1054/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 1054: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 1055/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2529\n",
      "Epoch 1055: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2529\n",
      "Epoch 1056/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2406\n",
      "Epoch 1056: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2407\n",
      "Epoch 1057/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2380\n",
      "Epoch 1057: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2381\n",
      "Epoch 1058/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2378\n",
      "Epoch 1058: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2372\n",
      "Epoch 1059/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1059: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2406\n",
      "Epoch 1060/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1060: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2411\n",
      "Epoch 1061/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2425\n",
      "Epoch 1061: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2425\n",
      "Epoch 1062/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1062: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2469\n",
      "Epoch 1063/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1063: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 1064/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2449\n",
      "Epoch 1064: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 1065/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2432\n",
      "Epoch 1065: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2428\n",
      "Epoch 1066/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2386\n",
      "Epoch 1066: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2386\n",
      "Epoch 1067/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2397\n",
      "Epoch 1067: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2401\n",
      "Epoch 1068/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1068: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2400\n",
      "Epoch 1069/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 1069: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1070/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2487\n",
      "Epoch 1070: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 1071/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2464\n",
      "Epoch 1071: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 1072/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2477\n",
      "Epoch 1072: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 1073/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1073: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2462\n",
      "Epoch 1074/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1074: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1075/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 1075: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 1076/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2477\n",
      "Epoch 1076: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 1077/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1077: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 1078/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1078: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 1079/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 1079: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2436\n",
      "Epoch 1080/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 1080: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 1081/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2415\n",
      "Epoch 1081: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2410\n",
      "Epoch 1082/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1082: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2463\n",
      "Epoch 1083/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2455\n",
      "Epoch 1083: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2461\n",
      "Epoch 1084/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1084: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 1085/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1085: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 1086/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2374\n",
      "Epoch 1086: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2377\n",
      "Epoch 1087/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2433\n",
      "Epoch 1087: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2437\n",
      "Epoch 1088/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 1088: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 1089/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2404\n",
      "Epoch 1089: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2401\n",
      "Epoch 1090/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2420\n",
      "Epoch 1090: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2424\n",
      "Epoch 1091/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2467\n",
      "Epoch 1091: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 1092/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1092: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 1093/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2401\n",
      "Epoch 1093: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2404\n",
      "Epoch 1094/10000\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1094: saving model to training3\\\n",
      "750/750 [==============================] - 1s 957us/step - loss: 0.2506\n",
      "Epoch 1095/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2550\n",
      "Epoch 1095: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2546\n",
      "Epoch 1096/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 1096: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2478\n",
      "Epoch 1097/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 1097: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2491\n",
      "Epoch 1098/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2480\n",
      "Epoch 1098: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2479\n",
      "Epoch 1099/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2505\n",
      "Epoch 1099: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2499\n",
      "Epoch 1100/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2509\n",
      "Epoch 1100: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2511\n",
      "Epoch 1101/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2480\n",
      "Epoch 1101: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 1102/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 1102: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2455\n",
      "Epoch 1103/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2527\n",
      "Epoch 1103: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 1104/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2541\n",
      "Epoch 1104: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2542\n",
      "Epoch 1105/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2593\n",
      "Epoch 1105: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2594\n",
      "Epoch 1106/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2568\n",
      "Epoch 1106: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2563\n",
      "Epoch 1107/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2485\n",
      "Epoch 1107: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 1108/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2399\n",
      "Epoch 1108: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2410\n",
      "Epoch 1109/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1109: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2407\n",
      "Epoch 1110/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2403\n",
      "Epoch 1110: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2403\n",
      "Epoch 1111/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2427\n",
      "Epoch 1111: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2434\n",
      "Epoch 1112/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2471\n",
      "Epoch 1112: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 1113/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 1113: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2481\n",
      "Epoch 1114/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2466\n",
      "Epoch 1114: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 1115/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1115: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 1116/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1116: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1117/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1117: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2438\n",
      "Epoch 1118/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2441\n",
      "Epoch 1118: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1119/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1119: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1120/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2461\n",
      "Epoch 1120: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2453\n",
      "Epoch 1121/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 1121: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 1122/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2449\n",
      "Epoch 1122: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2450\n",
      "Epoch 1123/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1123: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2432\n",
      "Epoch 1124/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1124: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2392\n",
      "Epoch 1125/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2417\n",
      "Epoch 1125: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2420\n",
      "Epoch 1126/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1126: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2467\n",
      "Epoch 1127/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2453\n",
      "Epoch 1127: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2454\n",
      "Epoch 1128/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2527\n",
      "Epoch 1128: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2523\n",
      "Epoch 1129/10000\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2477\n",
      "Epoch 1129: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2486\n",
      "Epoch 1130/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2509\n",
      "Epoch 1130: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 1131/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2506\n",
      "Epoch 1131: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2499\n",
      "Epoch 1132/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2546\n",
      "Epoch 1132: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2545\n",
      "Epoch 1133/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2578\n",
      "Epoch 1133: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2569\n",
      "Epoch 1134/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2587\n",
      "Epoch 1134: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2592\n",
      "Epoch 1135/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2569\n",
      "Epoch 1135: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2576\n",
      "Epoch 1136/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2543\n",
      "Epoch 1136: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2546\n",
      "Epoch 1137/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2523\n",
      "Epoch 1137: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2514\n",
      "Epoch 1138/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1138: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 1139/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2492\n",
      "Epoch 1139: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 1140/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2457\n",
      "Epoch 1140: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1141/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2432\n",
      "Epoch 1141: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2424\n",
      "Epoch 1142/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1142: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2409\n",
      "Epoch 1143/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2362\n",
      "Epoch 1143: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2362\n",
      "Epoch 1144/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2349\n",
      "Epoch 1144: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2352\n",
      "Epoch 1145/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2345\n",
      "Epoch 1145: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2348\n",
      "Epoch 1146/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1146: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1147/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "Epoch 1147: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2449\n",
      "Epoch 1148/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 1148: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2429\n",
      "Epoch 1149/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1149: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1150/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2402\n",
      "Epoch 1150: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2398\n",
      "Epoch 1151/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2385\n",
      "Epoch 1151: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2390\n",
      "Epoch 1152/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2394\n",
      "Epoch 1152: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2395\n",
      "Epoch 1153/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2365\n",
      "Epoch 1153: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2367\n",
      "Epoch 1154/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2413\n",
      "Epoch 1154: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2418\n",
      "Epoch 1155/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 1155: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2479\n",
      "Epoch 1156/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1156: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2467\n",
      "Epoch 1157/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 1157: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 1158/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1158: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 1159/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2489\n",
      "Epoch 1159: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 1160/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1160: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 1161/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1161: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1162/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2427\n",
      "Epoch 1162: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2427\n",
      "Epoch 1163/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1163: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 1164/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2485\n",
      "Epoch 1164: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 1165/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2411\n",
      "Epoch 1165: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2416\n",
      "Epoch 1166/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1166: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2438\n",
      "Epoch 1167/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2457\n",
      "Epoch 1167: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2444\n",
      "Epoch 1168/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2426\n",
      "Epoch 1168: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2427\n",
      "Epoch 1169/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2514\n",
      "Epoch 1169: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 1170/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2459\n",
      "Epoch 1170: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2459\n",
      "Epoch 1171/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 1171: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 1172/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2484\n",
      "Epoch 1172: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2481\n",
      "Epoch 1173/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1173: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2413\n",
      "Epoch 1174/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2409\n",
      "Epoch 1174: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2411\n",
      "Epoch 1175/10000\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 1175: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2454\n",
      "Epoch 1176/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2495\n",
      "Epoch 1176: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2495\n",
      "Epoch 1177/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 1177: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2473\n",
      "Epoch 1178/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1178: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2432\n",
      "Epoch 1179/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2459\n",
      "Epoch 1179: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2457\n",
      "Epoch 1180/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2467\n",
      "Epoch 1180: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 1181/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 1181: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2449\n",
      "Epoch 1182/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 1182: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2486\n",
      "Epoch 1183/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1183: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2418\n",
      "Epoch 1184/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1184: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1185/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1185: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2457\n",
      "Epoch 1186/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1186: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2422\n",
      "Epoch 1187/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2443\n",
      "Epoch 1187: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2446\n",
      "Epoch 1188/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1188: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1189/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1189: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2438\n",
      "Epoch 1190/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2433\n",
      "Epoch 1190: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 1191/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2383\n",
      "Epoch 1191: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2382\n",
      "Epoch 1192/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2393\n",
      "Epoch 1192: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2400\n",
      "Epoch 1193/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2421\n",
      "Epoch 1193: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2426\n",
      "Epoch 1194/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2518\n",
      "Epoch 1194: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 1195/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2526\n",
      "Epoch 1195: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2525\n",
      "Epoch 1196/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2592\n",
      "Epoch 1196: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2595\n",
      "Epoch 1197/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2679\n",
      "Epoch 1197: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2678\n",
      "Epoch 1198/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2573\n",
      "Epoch 1198: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2572\n",
      "Epoch 1199/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 1199: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 1200/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 1200: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2465\n",
      "Epoch 1201/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 1201: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2438\n",
      "Epoch 1202/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1202: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1203/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2439\n",
      "Epoch 1203: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2445\n",
      "Epoch 1204/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1204: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2416\n",
      "Epoch 1205/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1205: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2415\n",
      "Epoch 1206/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 1206: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2457\n",
      "Epoch 1207/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1207: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 1208/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2463\n",
      "Epoch 1208: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2454\n",
      "Epoch 1209/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 1209: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 1210/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2482\n",
      "Epoch 1210: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2484\n",
      "Epoch 1211/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 1211: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2460\n",
      "Epoch 1212/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2530\n",
      "Epoch 1212: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2526\n",
      "Epoch 1213/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2510\n",
      "Epoch 1213: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 1214/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2507\n",
      "Epoch 1214: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2506\n",
      "Epoch 1215/10000\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2496\n",
      "Epoch 1215: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2482\n",
      "Epoch 1216/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1216: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 1217/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2453\n",
      "Epoch 1217: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 1218/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2498\n",
      "Epoch 1218: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 1219/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2487\n",
      "Epoch 1219: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 1220/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2475\n",
      "Epoch 1220: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2477\n",
      "Epoch 1221/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2467\n",
      "Epoch 1221: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 1222/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2563\n",
      "Epoch 1222: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2570\n",
      "Epoch 1223/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2499\n",
      "Epoch 1223: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2502\n",
      "Epoch 1224/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2433\n",
      "Epoch 1224: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2434\n",
      "Epoch 1225/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2489\n",
      "Epoch 1225: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 1226/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1226: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 1227/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 1227: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 1228/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1228: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2501\n",
      "Epoch 1229/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 1229: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 1230/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1230: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 1231/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2470\n",
      "Epoch 1231: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 1232/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2473\n",
      "Epoch 1232: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 1233/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2547\n",
      "Epoch 1233: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2545\n",
      "Epoch 1234/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2572\n",
      "Epoch 1234: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2581\n",
      "Epoch 1235/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2543\n",
      "Epoch 1235: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2544\n",
      "Epoch 1236/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2519\n",
      "Epoch 1236: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 1237/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2548\n",
      "Epoch 1237: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2551\n",
      "Epoch 1238/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2533\n",
      "Epoch 1238: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2540\n",
      "Epoch 1239/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2601\n",
      "Epoch 1239: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2608\n",
      "Epoch 1240/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2530\n",
      "Epoch 1240: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 1241/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2471\n",
      "Epoch 1241: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 1242/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1242: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 1243/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2436\n",
      "Epoch 1243: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 1244/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1244: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2408\n",
      "Epoch 1245/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2394\n",
      "Epoch 1245: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2399\n",
      "Epoch 1246/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 1246: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2481\n",
      "Epoch 1247/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2471\n",
      "Epoch 1247: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2466\n",
      "Epoch 1248/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1248: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 1249/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "Epoch 1249: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2443\n",
      "Epoch 1250/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2490\n",
      "Epoch 1250: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 1251/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1251: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 1252/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2418\n",
      "Epoch 1252: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2423\n",
      "Epoch 1253/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2420\n",
      "Epoch 1253: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 1254/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2405\n",
      "Epoch 1254: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2399\n",
      "Epoch 1255/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2392\n",
      "Epoch 1255: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2392\n",
      "Epoch 1256/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2384\n",
      "Epoch 1256: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2385\n",
      "Epoch 1257/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2404\n",
      "Epoch 1257: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2407\n",
      "Epoch 1258/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2415\n",
      "Epoch 1258: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2413\n",
      "Epoch 1259/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1259: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2426\n",
      "Epoch 1260/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2413\n",
      "Epoch 1260: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 1261/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1261: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2458\n",
      "Epoch 1262/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 1262: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 1263/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1263: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2438\n",
      "Epoch 1264/10000\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2457\n",
      "Epoch 1264: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 1265/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2367\n",
      "Epoch 1265: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2368\n",
      "Epoch 1266/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2370\n",
      "Epoch 1266: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2369\n",
      "Epoch 1267/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1267: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2397\n",
      "Epoch 1268/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2388\n",
      "Epoch 1268: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2387\n",
      "Epoch 1269/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 1269: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1270/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1270: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2438\n",
      "Epoch 1271/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 1271: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 1272/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 1272: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2441\n",
      "Epoch 1273/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2396\n",
      "Epoch 1273: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2398\n",
      "Epoch 1274/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2382\n",
      "Epoch 1274: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2377\n",
      "Epoch 1275/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2399\n",
      "Epoch 1275: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2399\n",
      "Epoch 1276/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2411\n",
      "Epoch 1276: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1277/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1277: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2410\n",
      "Epoch 1278/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2389\n",
      "Epoch 1278: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2387\n",
      "Epoch 1279/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 1279: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2474\n",
      "Epoch 1280/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1280: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2430\n",
      "Epoch 1281/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1281: saving model to training3\\\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2438\n",
      "Epoch 1282/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2396\n",
      "Epoch 1282: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2404\n",
      "Epoch 1283/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 1283: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2449\n",
      "Epoch 1284/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "Epoch 1284: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 1285/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2581\n",
      "Epoch 1285: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2578\n",
      "Epoch 1286/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2609\n",
      "Epoch 1286: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2604\n",
      "Epoch 1287/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2618\n",
      "Epoch 1287: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2617\n",
      "Epoch 1288/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2552\n",
      "Epoch 1288: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2544\n",
      "Epoch 1289/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2470\n",
      "Epoch 1289: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 1290/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2455\n",
      "Epoch 1290: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 1291/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 1291: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2491\n",
      "Epoch 1292/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2551\n",
      "Epoch 1292: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2555\n",
      "Epoch 1293/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2586\n",
      "Epoch 1293: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2584\n",
      "Epoch 1294/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2572\n",
      "Epoch 1294: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2573\n",
      "Epoch 1295/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2487\n",
      "Epoch 1295: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2485\n",
      "Epoch 1296/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2520\n",
      "Epoch 1296: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2522\n",
      "Epoch 1297/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2533\n",
      "Epoch 1297: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2534\n",
      "Epoch 1298/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2500\n",
      "Epoch 1298: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2500\n",
      "Epoch 1299/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2398\n",
      "Epoch 1299: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2400\n",
      "Epoch 1300/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2432\n",
      "Epoch 1300: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 1301/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2483\n",
      "Epoch 1301: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2494\n",
      "Epoch 1302/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2539\n",
      "Epoch 1302: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2537\n",
      "Epoch 1303/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2575\n",
      "Epoch 1303: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2574\n",
      "Epoch 1304/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2504\n",
      "Epoch 1304: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 1305/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2495\n",
      "Epoch 1305: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 1306/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2475\n",
      "Epoch 1306: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2477\n",
      "Epoch 1307/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2497\n",
      "Epoch 1307: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 1308/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1308: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2436\n",
      "Epoch 1309/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 1309: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 1310/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2515\n",
      "Epoch 1310: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2513\n",
      "Epoch 1311/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2517\n",
      "Epoch 1311: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2516\n",
      "Epoch 1312/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2456\n",
      "Epoch 1312: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2454\n",
      "Epoch 1313/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2425\n",
      "Epoch 1313: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 1314/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2522\n",
      "Epoch 1314: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2526\n",
      "Epoch 1315/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2554\n",
      "Epoch 1315: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2552\n",
      "Epoch 1316/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2479\n",
      "Epoch 1316: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 1317/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1317: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 1318/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2379\n",
      "Epoch 1318: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2376\n",
      "Epoch 1319/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2373\n",
      "Epoch 1319: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2374\n",
      "Epoch 1320/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2424\n",
      "Epoch 1320: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2422\n",
      "Epoch 1321/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1321: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 1322/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 1322: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2445\n",
      "Epoch 1323/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1323: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2413\n",
      "Epoch 1324/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2453\n",
      "Epoch 1324: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 1325/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2445\n",
      "Epoch 1325: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 1326/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2459\n",
      "Epoch 1326: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2455\n",
      "Epoch 1327/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1327: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 1328/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2423\n",
      "Epoch 1328: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2419\n",
      "Epoch 1329/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2369\n",
      "Epoch 1329: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2376\n",
      "Epoch 1330/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2348\n",
      "Epoch 1330: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2349\n",
      "Epoch 1331/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2358\n",
      "Epoch 1331: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2360\n",
      "Epoch 1332/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2417\n",
      "Epoch 1332: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2420\n",
      "Epoch 1333/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1333: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 1334/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1334: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2410\n",
      "Epoch 1335/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 1335: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2468\n",
      "Epoch 1336/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2508\n",
      "Epoch 1336: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 1337/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2450\n",
      "Epoch 1337: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2448\n",
      "Epoch 1338/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1338: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 1339/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2475\n",
      "Epoch 1339: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2477\n",
      "Epoch 1340/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 1340: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2482\n",
      "Epoch 1341/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 1341: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 1342/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1342: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 1343/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1343: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2445\n",
      "Epoch 1344/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 1344: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2437\n",
      "Epoch 1345/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1345: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1346/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2392\n",
      "Epoch 1346: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2395\n",
      "Epoch 1347/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2443\n",
      "Epoch 1347: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2450\n",
      "Epoch 1348/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2461\n",
      "Epoch 1348: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 1349/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2537\n",
      "Epoch 1349: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2532\n",
      "Epoch 1350/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2497\n",
      "Epoch 1350: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 1351/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1351: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1352/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1352: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2427\n",
      "Epoch 1353/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2368\n",
      "Epoch 1353: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2368\n",
      "Epoch 1354/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2398\n",
      "Epoch 1354: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2397\n",
      "Epoch 1355/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1355: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2388\n",
      "Epoch 1356/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2517\n",
      "Epoch 1356: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2515\n",
      "Epoch 1357/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2531\n",
      "Epoch 1357: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2532\n",
      "Epoch 1358/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2586\n",
      "Epoch 1358: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2587\n",
      "Epoch 1359/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2515\n",
      "Epoch 1359: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2515\n",
      "Epoch 1360/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2559\n",
      "Epoch 1360: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2566\n",
      "Epoch 1361/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2509\n",
      "Epoch 1361: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 1362/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1362: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 1363/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 1363: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 1364/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2492\n",
      "Epoch 1364: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 1365/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2509\n",
      "Epoch 1365: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2512\n",
      "Epoch 1366/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2560\n",
      "Epoch 1366: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2559\n",
      "Epoch 1367/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2568\n",
      "Epoch 1367: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2569\n",
      "Epoch 1368/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2516\n",
      "Epoch 1368: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2514\n",
      "Epoch 1369/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "Epoch 1369: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2488\n",
      "Epoch 1370/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1370: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2442\n",
      "Epoch 1371/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "Epoch 1371: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2517\n",
      "Epoch 1372/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2486\n",
      "Epoch 1372: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2486\n",
      "Epoch 1373/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2490\n",
      "Epoch 1373: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2483\n",
      "Epoch 1374/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2491\n",
      "Epoch 1374: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 1375/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2487\n",
      "Epoch 1375: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 1376/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 1376: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 1377/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1377: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2475\n",
      "Epoch 1378/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2496\n",
      "Epoch 1378: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2493\n",
      "Epoch 1379/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 1379: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 1380/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2495\n",
      "Epoch 1380: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2495\n",
      "Epoch 1381/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2395\n",
      "Epoch 1381: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2397\n",
      "Epoch 1382/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2394\n",
      "Epoch 1382: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2394\n",
      "Epoch 1383/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2363\n",
      "Epoch 1383: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2368\n",
      "Epoch 1384/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2380\n",
      "Epoch 1384: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2378\n",
      "Epoch 1385/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1385: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2416\n",
      "Epoch 1386/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 1386: saving model to training3\\\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2427\n",
      "Epoch 1387/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 1387: saving model to training3\\\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2431\n",
      "Epoch 1388/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2433\n",
      "Epoch 1388: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 1389/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2367\n",
      "Epoch 1389: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2369\n",
      "Epoch 1390/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2384\n",
      "Epoch 1390: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2380\n",
      "Epoch 1391/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2350\n",
      "Epoch 1391: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2346\n",
      "Epoch 1392/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2368\n",
      "Epoch 1392: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2370\n",
      "Epoch 1393/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 1393: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 1394/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2417\n",
      "Epoch 1394: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1395/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2411\n",
      "Epoch 1395: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2398\n",
      "Epoch 1396/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2399\n",
      "Epoch 1396: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2398\n",
      "Epoch 1397/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2447\n",
      "Epoch 1397: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 1398/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2501\n",
      "Epoch 1398: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2500\n",
      "Epoch 1399/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2485\n",
      "Epoch 1399: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2490\n",
      "Epoch 1400/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2417\n",
      "Epoch 1400: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1401/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2352\n",
      "Epoch 1401: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2349\n",
      "Epoch 1402/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2365\n",
      "Epoch 1402: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2371\n",
      "Epoch 1403/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2386\n",
      "Epoch 1403: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2391\n",
      "Epoch 1404/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2389\n",
      "Epoch 1404: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2377\n",
      "Epoch 1405/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2389\n",
      "Epoch 1405: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 1406/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2394\n",
      "Epoch 1406: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2407\n",
      "Epoch 1407/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1407: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2413\n",
      "Epoch 1408/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2389\n",
      "Epoch 1408: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 1409/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2398\n",
      "Epoch 1409: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2404\n",
      "Epoch 1410/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2392\n",
      "Epoch 1410: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2396\n",
      "Epoch 1411/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1411: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 1412/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1412: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2396\n",
      "Epoch 1413/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2429\n",
      "Epoch 1413: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 1414/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2385\n",
      "Epoch 1414: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2400\n",
      "Epoch 1415/10000\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2365\n",
      "Epoch 1415: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2370\n",
      "Epoch 1416/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2383\n",
      "Epoch 1416: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2394\n",
      "Epoch 1417/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2361\n",
      "Epoch 1417: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2365\n",
      "Epoch 1418/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2336\n",
      "Epoch 1418: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2339\n",
      "Epoch 1419/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2341\n",
      "Epoch 1419: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2341\n",
      "Epoch 1420/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2377\n",
      "Epoch 1420: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2377\n",
      "Epoch 1421/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2369\n",
      "Epoch 1421: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2371\n",
      "Epoch 1422/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2396\n",
      "Epoch 1422: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2395\n",
      "Epoch 1423/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2402\n",
      "Epoch 1423: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2403\n",
      "Epoch 1424/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1424: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 1425/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1425: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 1426/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2544\n",
      "Epoch 1426: saving model to training3\\\n",
      "750/750 [==============================] - 1s 927us/step - loss: 0.2553\n",
      "Epoch 1427/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2534\n",
      "Epoch 1427: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2535\n",
      "Epoch 1428/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2545\n",
      "Epoch 1428: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2548\n",
      "Epoch 1429/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 1429: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2492\n",
      "Epoch 1430/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 1430: saving model to training3\\\n",
      "750/750 [==============================] - 1s 918us/step - loss: 0.2472\n",
      "Epoch 1431/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1431: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2439\n",
      "Epoch 1432/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2425\n",
      "Epoch 1432: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1433/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1433: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 1434/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2482\n",
      "Epoch 1434: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2489\n",
      "Epoch 1435/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2466\n",
      "Epoch 1435: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2477\n",
      "Epoch 1436/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1436: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 1437/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2401\n",
      "Epoch 1437: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2406\n",
      "Epoch 1438/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2484\n",
      "Epoch 1438: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2476\n",
      "Epoch 1439/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1439: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 1440/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2469\n",
      "Epoch 1440: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 1441/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2413\n",
      "Epoch 1441: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2418\n",
      "Epoch 1442/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 1442: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2434\n",
      "Epoch 1443/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1443: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2502\n",
      "Epoch 1444/10000\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2461\n",
      "Epoch 1444: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2455\n",
      "Epoch 1445/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2374\n",
      "Epoch 1445: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2372\n",
      "Epoch 1446/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1446: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2424\n",
      "Epoch 1447/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 1447: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 1448/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2402\n",
      "Epoch 1448: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2402\n",
      "Epoch 1449/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2417\n",
      "Epoch 1449: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2418\n",
      "Epoch 1450/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2361\n",
      "Epoch 1450: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2365\n",
      "Epoch 1451/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2358\n",
      "Epoch 1451: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2362\n",
      "Epoch 1452/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1452: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1453/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2427\n",
      "Epoch 1453: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2422\n",
      "Epoch 1454/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2457\n",
      "Epoch 1454: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1455/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2393\n",
      "Epoch 1455: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2396\n",
      "Epoch 1456/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2345\n",
      "Epoch 1456: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2347\n",
      "Epoch 1457/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2378\n",
      "Epoch 1457: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2379\n",
      "Epoch 1458/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1458: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 1459/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 1459: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 1460/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1460: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2456\n",
      "Epoch 1461/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1461: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2422\n",
      "Epoch 1462/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1462: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2437\n",
      "Epoch 1463/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1463: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2395\n",
      "Epoch 1464/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2385\n",
      "Epoch 1464: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2385\n",
      "Epoch 1465/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2368\n",
      "Epoch 1465: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2376\n",
      "Epoch 1466/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2405\n",
      "Epoch 1466: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2404\n",
      "Epoch 1467/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2501\n",
      "Epoch 1467: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 1468/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2516\n",
      "Epoch 1468: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 1469/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2475\n",
      "Epoch 1469: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 1470/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2495\n",
      "Epoch 1470: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2494\n",
      "Epoch 1471/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2508\n",
      "Epoch 1471: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2509\n",
      "Epoch 1472/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1472: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 1473/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1473: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 1474/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2363\n",
      "Epoch 1474: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2363\n",
      "Epoch 1475/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2413\n",
      "Epoch 1475: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 1476/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2392\n",
      "Epoch 1476: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2390\n",
      "Epoch 1477/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2408\n",
      "Epoch 1477: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2407\n",
      "Epoch 1478/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2389\n",
      "Epoch 1478: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2391\n",
      "Epoch 1479/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2348\n",
      "Epoch 1479: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2346\n",
      "Epoch 1480/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2381\n",
      "Epoch 1480: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2381\n",
      "Epoch 1481/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2350\n",
      "Epoch 1481: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2349\n",
      "Epoch 1482/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1482: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2444\n",
      "Epoch 1483/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1483: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 1484/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2405\n",
      "Epoch 1484: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1485/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "Epoch 1485: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2440\n",
      "Epoch 1486/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2407\n",
      "Epoch 1486: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2411\n",
      "Epoch 1487/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2427\n",
      "Epoch 1487: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1488/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1488: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 1489/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2429\n",
      "Epoch 1489: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2431\n",
      "Epoch 1490/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2459\n",
      "Epoch 1490: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 1491/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2428\n",
      "Epoch 1491: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2427\n",
      "Epoch 1492/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2463\n",
      "Epoch 1492: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 1493/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1493: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 1494/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2441\n",
      "Epoch 1494: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 1495/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1495: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2455\n",
      "Epoch 1496/10000\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2465\n",
      "Epoch 1496: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2474\n",
      "Epoch 1497/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1497: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2408\n",
      "Epoch 1498/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2363\n",
      "Epoch 1498: saving model to training3\\\n",
      "750/750 [==============================] - 1s 968us/step - loss: 0.2365\n",
      "Epoch 1499/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2376\n",
      "Epoch 1499: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2375\n",
      "Epoch 1500/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2439\n",
      "Epoch 1500: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1501/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "Epoch 1501: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2482\n",
      "Epoch 1502/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2504\n",
      "Epoch 1502: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2508\n",
      "Epoch 1503/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2424\n",
      "Epoch 1503: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2422\n",
      "Epoch 1504/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2454\n",
      "Epoch 1504: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 1505/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2497\n",
      "Epoch 1505: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 1506/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2495\n",
      "Epoch 1506: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2491\n",
      "Epoch 1507/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1507: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 1508/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2446\n",
      "Epoch 1508: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2445\n",
      "Epoch 1509/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2477\n",
      "Epoch 1509: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 1510/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "Epoch 1510: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2512\n",
      "Epoch 1511/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1511: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2461\n",
      "Epoch 1512/10000\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1512: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1513/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2438\n",
      "Epoch 1513: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2430\n",
      "Epoch 1514/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2494\n",
      "Epoch 1514: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2496\n",
      "Epoch 1515/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2554\n",
      "Epoch 1515: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2550\n",
      "Epoch 1516/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2579\n",
      "Epoch 1516: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2572\n",
      "Epoch 1517/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2521\n",
      "Epoch 1517: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2521\n",
      "Epoch 1518/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2485\n",
      "Epoch 1518: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2487\n",
      "Epoch 1519/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "Epoch 1519: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2512\n",
      "Epoch 1520/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2525\n",
      "Epoch 1520: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 1521/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2473\n",
      "Epoch 1521: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 1522/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2478\n",
      "Epoch 1522: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2479\n",
      "Epoch 1523/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2478\n",
      "Epoch 1523: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 1524/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2405\n",
      "Epoch 1524: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2404\n",
      "Epoch 1525/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2359\n",
      "Epoch 1525: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2357\n",
      "Epoch 1526/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2395\n",
      "Epoch 1526: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2403\n",
      "Epoch 1527/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2476\n",
      "Epoch 1527: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2480\n",
      "Epoch 1528/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2431\n",
      "Epoch 1528: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2432\n",
      "Epoch 1529/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2401\n",
      "Epoch 1529: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2407\n",
      "Epoch 1530/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2406\n",
      "Epoch 1530: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2404\n",
      "Epoch 1531/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2372\n",
      "Epoch 1531: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2382\n",
      "Epoch 1532/10000\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2349\n",
      "Epoch 1532: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2348\n",
      "Epoch 1533/10000\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2386\n",
      "Epoch 1533: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 1534/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2431\n",
      "Epoch 1534: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2443\n",
      "Epoch 1535/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2500\n",
      "Epoch 1535: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2507\n",
      "Epoch 1536/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2534\n",
      "Epoch 1536: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2543\n",
      "Epoch 1537/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2506\n",
      "Epoch 1537: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 1538/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2482\n",
      "Epoch 1538: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2478\n",
      "Epoch 1539/10000\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2405\n",
      "Epoch 1539: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2402\n",
      "Epoch 1540/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2362\n",
      "Epoch 1540: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2363\n",
      "Epoch 1541/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2365\n",
      "Epoch 1541: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2371\n",
      "Epoch 1542/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2391\n",
      "Epoch 1542: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2391\n",
      "Epoch 1543/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2394\n",
      "Epoch 1543: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 1544/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2462\n",
      "Epoch 1544: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 1545/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2444\n",
      "Epoch 1545: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 1546/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2423\n",
      "Epoch 1546: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2423\n",
      "Epoch 1547/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2428\n",
      "Epoch 1547: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2427\n",
      "Epoch 1548/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2405\n",
      "Epoch 1548: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2406\n",
      "Epoch 1549/10000\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2381\n",
      "Epoch 1549: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2368\n",
      "Epoch 1550/10000\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2381\n",
      "Epoch 1550: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2385\n",
      "Epoch 1551/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1551: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2469\n",
      "Epoch 1552/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2527\n",
      "Epoch 1552: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2523\n",
      "Epoch 1553/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2537\n",
      "Epoch 1553: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2533\n",
      "Epoch 1554/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 1554: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2465\n",
      "Epoch 1555/10000\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "Epoch 1555: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2446\n",
      "Epoch 1556/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1556: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2414\n",
      "Epoch 1557/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2375\n",
      "Epoch 1557: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2392\n",
      "Epoch 1558/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2385\n",
      "Epoch 1558: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2385\n",
      "Epoch 1559/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2367\n",
      "Epoch 1559: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2372\n",
      "Epoch 1560/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1560: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2408\n",
      "Epoch 1561/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 1561: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2453\n",
      "Epoch 1562/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2498\n",
      "Epoch 1562: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2497\n",
      "Epoch 1563/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2531\n",
      "Epoch 1563: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2530\n",
      "Epoch 1564/10000\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2459\n",
      "Epoch 1564: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 1565/10000\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1565: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2420\n",
      "Epoch 1566/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2458\n",
      "Epoch 1566: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2458\n",
      "Epoch 1567/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1567: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 1568/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2410\n",
      "Epoch 1568: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2413\n",
      "Epoch 1569/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1569: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2449\n",
      "Epoch 1570/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2420\n",
      "Epoch 1570: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 1571/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1571: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2401\n",
      "Epoch 1572/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2386\n",
      "Epoch 1572: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2385\n",
      "Epoch 1573/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2420\n",
      "Epoch 1573: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 1574/10000\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1574: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2415\n",
      "Epoch 1575/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1575: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2397\n",
      "Epoch 1576/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1576: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2385\n",
      "Epoch 1577/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2383\n",
      "Epoch 1577: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2378\n",
      "Epoch 1578/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2408\n",
      "Epoch 1578: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2410\n",
      "Epoch 1579/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1579: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2470\n",
      "Epoch 1580/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1580: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2451\n",
      "Epoch 1581/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2493\n",
      "Epoch 1581: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2503\n",
      "Epoch 1582/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2469\n",
      "Epoch 1582: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 1583/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2481\n",
      "Epoch 1583: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 1584/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2443\n",
      "Epoch 1584: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2441\n",
      "Epoch 1585/10000\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1585: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2423\n",
      "Epoch 1586/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2396\n",
      "Epoch 1586: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2394\n",
      "Epoch 1587/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2322\n",
      "Epoch 1587: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2313\n",
      "Epoch 1588/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2370\n",
      "Epoch 1588: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2368\n",
      "Epoch 1589/10000\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2299\n",
      "Epoch 1589: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2301\n",
      "Epoch 1590/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2309\n",
      "Epoch 1590: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2310\n",
      "Epoch 1591/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2448\n",
      "Epoch 1591: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 1592/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1592: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2384\n",
      "Epoch 1593/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2414\n",
      "Epoch 1593: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1594/10000\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2443\n",
      "Epoch 1594: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 1595/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2485\n",
      "Epoch 1595: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2484\n",
      "Epoch 1596/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2393\n",
      "Epoch 1596: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2407\n",
      "Epoch 1597/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1597: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2432\n",
      "Epoch 1598/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2461\n",
      "Epoch 1598: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2467\n",
      "Epoch 1599/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1599: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 1600/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 1600: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2452\n",
      "Epoch 1601/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2465\n",
      "Epoch 1601: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 1602/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2521\n",
      "Epoch 1602: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2520\n",
      "Epoch 1603/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "Epoch 1603: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2468\n",
      "Epoch 1604/10000\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2411\n",
      "Epoch 1604: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2410\n",
      "Epoch 1605/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2347\n",
      "Epoch 1605: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2348\n",
      "Epoch 1606/10000\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2361\n",
      "Epoch 1606: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2359\n",
      "Epoch 1607/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1607: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2386\n",
      "Epoch 1608/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2330\n",
      "Epoch 1608: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2333\n",
      "Epoch 1609/10000\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2390\n",
      "Epoch 1609: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2391\n",
      "Epoch 1610/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2413\n",
      "Epoch 1610: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2414\n",
      "Epoch 1611/10000\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2376\n",
      "Epoch 1611: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2387\n",
      "Epoch 1612/10000\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2393\n",
      "Epoch 1612: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2391\n",
      "Epoch 1613/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1613: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2518\n",
      "Epoch 1614/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2503\n",
      "Epoch 1614: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2506\n",
      "Epoch 1615/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2433\n",
      "Epoch 1615: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1000us/step - loss: 0.2433\n",
      "Epoch 1616/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2398\n",
      "Epoch 1616: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2400\n",
      "Epoch 1617/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2360\n",
      "Epoch 1617: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2363\n",
      "Epoch 1618/10000\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2408\n",
      "Epoch 1618: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2417\n",
      "Epoch 1619/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2398\n",
      "Epoch 1619: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2389\n",
      "Epoch 1620/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2420\n",
      "Epoch 1620: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2415\n",
      "Epoch 1621/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1621: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2406\n",
      "Epoch 1622/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2417\n",
      "Epoch 1622: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1623/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2474\n",
      "Epoch 1623: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 1624/10000\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1624: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2473\n",
      "Epoch 1625/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2467\n",
      "Epoch 1625: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2466\n",
      "Epoch 1626/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2551\n",
      "Epoch 1626: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2547\n",
      "Epoch 1627/10000\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2464\n",
      "Epoch 1627: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2457\n",
      "Epoch 1628/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2433\n",
      "Epoch 1628: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2435\n",
      "Epoch 1629/10000\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2448\n",
      "Epoch 1629: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2464\n",
      "Epoch 1630/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2477\n",
      "Epoch 1630: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2482\n",
      "Epoch 1631/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2522\n",
      "Epoch 1631: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2526\n",
      "Epoch 1632/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2551\n",
      "Epoch 1632: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2541\n",
      "Epoch 1633/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2551\n",
      "Epoch 1633: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2542\n",
      "Epoch 1634/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2585\n",
      "Epoch 1634: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2584\n",
      "Epoch 1635/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2576\n",
      "Epoch 1635: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2583\n",
      "Epoch 1636/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2536\n",
      "Epoch 1636: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2536\n",
      "Epoch 1637/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2561\n",
      "Epoch 1637: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2554\n",
      "Epoch 1638/10000\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1638: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2434\n",
      "Epoch 1639/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2356\n",
      "Epoch 1639: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2350\n",
      "Epoch 1640/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2343\n",
      "Epoch 1640: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2342\n",
      "Epoch 1641/10000\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2308\n",
      "Epoch 1641: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2319\n",
      "Epoch 1642/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2332\n",
      "Epoch 1642: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2333\n",
      "Epoch 1643/10000\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2445\n",
      "Epoch 1643: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2450\n",
      "Epoch 1644/10000\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2382\n",
      "Epoch 1644: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2383\n",
      "Epoch 1645/10000\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2389\n",
      "Epoch 1645: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2390\n",
      "Epoch 1646/10000\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1646: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2388\n",
      "Epoch 1647/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2404\n",
      "Epoch 1647: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2403\n",
      "Epoch 1648/10000\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2420\n",
      "Epoch 1648: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2421\n",
      "Epoch 1649/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2413\n",
      "Epoch 1649: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2412\n",
      "Epoch 1650/10000\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2413\n",
      "Epoch 1650: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2418\n",
      "Epoch 1651/10000\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2421\n",
      "Epoch 1651: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2424\n",
      "Epoch 1652/10000\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2355\n",
      "Epoch 1652: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2364\n",
      "Epoch 1653/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2375\n",
      "Epoch 1653: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2369\n",
      "Epoch 1654/10000\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2328\n",
      "Epoch 1654: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2324\n",
      "Epoch 1655/10000\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2361\n",
      "Epoch 1655: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2364\n",
      "Epoch 1656/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2496\n",
      "Epoch 1656: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2498\n",
      "Epoch 1657/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1657: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2471\n",
      "Epoch 1658/10000\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2388\n",
      "Epoch 1658: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2392\n",
      "Epoch 1659/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2390\n",
      "Epoch 1659: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2391\n",
      "Epoch 1660/10000\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2379\n",
      "Epoch 1660: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2378\n",
      "Epoch 1661/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2432\n",
      "Epoch 1661: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2433\n",
      "Epoch 1662/10000\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2400\n",
      "Epoch 1662: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2401\n",
      "Epoch 1663/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2465\n",
      "Epoch 1663: saving model to training3\\\n",
      "750/750 [==============================] - 1s 994us/step - loss: 0.2458\n",
      "Epoch 1664/10000\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2445\n",
      "Epoch 1664: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 1665/10000\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2430\n",
      "Epoch 1665: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 1666/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2434\n",
      "Epoch 1666: saving model to training3\\\n",
      "750/750 [==============================] - 1s 988us/step - loss: 0.2435\n",
      "Epoch 1667/10000\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2415\n",
      "Epoch 1667: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2419\n",
      "Epoch 1668/10000\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2518\n",
      "Epoch 1668: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2520\n",
      "Epoch 1669/10000\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "Epoch 1669: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2454\n",
      "Epoch 1670/10000\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2423\n",
      "Epoch 1670: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2427\n",
      "Epoch 1671/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "Epoch 1671: saving model to training3\\\n",
      "750/750 [==============================] - 1s 989us/step - loss: 0.2494\n",
      "Epoch 1672/10000\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2491\n",
      "Epoch 1672: saving model to training3\\\n",
      "750/750 [==============================] - 1s 988us/step - loss: 0.2496\n",
      "Epoch 1673/10000\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2464\n",
      "Epoch 1673: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2459\n",
      "Epoch 1674/10000\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2424\n",
      "Epoch 1674: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2424\n",
      "Epoch 1675/10000\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2406\n",
      "Epoch 1675: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2404\n",
      "Epoch 1676/10000\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2411\n",
      "Epoch 1676: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2423\n",
      "Epoch 1677/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2429\n",
      "Epoch 1677: saving model to training3\\\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2428\n",
      "Epoch 1678/10000\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "Epoch 1678: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2415\n",
      "Epoch 1679/10000\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2399\n",
      "Epoch 1679: saving model to training3\\\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2396\n",
      "Epoch 1680/10000\n",
      "148/750 [====>.........................] - ETA: 0s - loss: 0.2301"
     ]
    }
   ],
   "source": [
    "nn.fit(x_train[:24000], y_train[:24000], epochs = 10000, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.41192968102835\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "starting_point = 23922\n",
    "end_point = 25122\n",
    "output = np.zeros(end_point - starting_point)\n",
    "mistakes2 = np.zeros(end_point - starting_point)\n",
    "balance = 100\n",
    "btc = 0\n",
    "balance_array = []\n",
    "btc_array = []\n",
    "prev = [0 for _ in range(11)]\n",
    "\n",
    "for num in range(starting_point, end_point):\n",
    "    prediction = nn.predict(np.array([fill_single_pos(train_array, AVG_OFFSETS, OFFSET, num)]))\n",
    "    prediction[0, 0] = round(prediction[0, 0])\n",
    "    if prev.count(prediction[0, 0]) <= 4:\n",
    "        if prediction[0, 0] == 0:\n",
    "            balance /= 2\n",
    "            btc += balance / train_array[num] * 0.9975\n",
    "        else:\n",
    "            btc /= 2\n",
    "            balance += btc * train_array[num] * 0.9975\n",
    "    prev[num % len(prev)] = 0 if train_array[num] - train_array[num - 1] > 0 else 1\n",
    "    balance_array.append(balance)\n",
    "    btc_array.append(btc)\n",
    "    output[num - starting_point] = prediction[0, 0]\n",
    "    mistakes2[num - starting_point] = train_array[num] - train_array[num + RESULT_OFFSET]\n",
    "\n",
    "print(balance + btc * train_array[end_point])\n",
    "\n",
    "plt.plot([x for x in range(len(mistakes2))], mistakes2, color = 'blue')\n",
    "plt.savefig(f'{IMAGES_FOLDER}png/mistakes.png')\n",
    "plt.close()\n",
    "plt.plot([x for x in range(len(output))], output, color = 'red')\n",
    "plt.savefig(f'{IMAGES_FOLDER}png/predictions.png')\n",
    "plt.close()\n",
    "plt.plot([x for x in range(len(btc_array))], btc_array, color = 'orange')\n",
    "plt.savefig(f'{IMAGES_FOLDER}png/btc.png')\n",
    "plt.close()\n",
    "plt.plot([x for x in range(len(balance_array))], balance_array, color = 'green')\n",
    "plt.savefig(f'{IMAGES_FOLDER}png/balance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8911874e-09\n"
     ]
    }
   ],
   "source": [
    "last = [63800.84,63738.93,63624.51,63878.34,64061.29,63835.77,63477.25,63744.64,63577.66,63546.03,63608.80,64752.01,64710.63,64639.35,64693.40,64142.33,63952.02,64396.23,64372.91,64294.46,64403.43]\n",
    "print(nn.predict(np.array([fill_single_pos(last, AVG_OFFSETS, OFFSET, 19)]))[0, 0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "115b2e483176af9c8d93844520f433f820dde6182ae62898d2e527a6cf696ddb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
